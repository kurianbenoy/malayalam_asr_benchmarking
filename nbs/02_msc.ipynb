{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a296e77f-7e61-4016-8d06-cd082a7ce4d9",
   "metadata": {},
   "source": [
    "# Evaluation Malayalam Speech Corpus(MSC) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24a8420-9224-4b06-9bd0-bf39f5e9da47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp msc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47329ad1-4301-4cd4-a02f-8d6f07708e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71a3422-9b03-490e-a61c-817c57751b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import time\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, Audio\n",
    "from jiwer import wer, cer\n",
    "from transformers import pipeline\n",
    "\n",
    "from malayalam_asr_benchmarking.utils import whisper_norm, is_target_text_in_range, get_text, normalise, data, get_model_size, clear_gpu_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8256347b-c03b-462c-9072-be56e005fd95",
   "metadata": {},
   "source": [
    "## Loading dataset and evaluating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93bf399-397b-424a-8284-c9719ebd15a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_malayalam_speech_corpus_dataset():\n",
    "    dataset = load_dataset(\n",
    "            \"thennal/msc\",\n",
    "            split=\"train\"\n",
    "    )\n",
    "    dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "    dataset = dataset.map(normalise)\n",
    "    dataset = dataset.filter(is_target_text_in_range, input_columns=[\"norm_text\"])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1db601-1cf3-4d50-a9be-26e919e2576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def evaluate_whisper_model_msc(\n",
    "        model_name: str, # The model name\n",
    "        werlist: List[float], # WER List\n",
    "        cerlist: List[float], # CER list\n",
    "        modelsizelist: List[str], # model size list\n",
    "        timelist: List[float], # time(s) list\n",
    "        bs:int =16, # batch size\n",
    ")->None:\n",
    "    whisper_asr = pipeline(\n",
    "            \"automatic-speech-recognition\", model=model_name, device=0\n",
    "        )\n",
    "    dataset = load_malayalam_speech_corpus_dataset()\n",
    "    \n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    start = time.time()\n",
    "    for out in whisper_asr(data(dataset), batch_size=bs):\n",
    "        predictions.append(whisper_norm(out[\"text\"]))\n",
    "        references.append(out[\"reference\"][0])\n",
    "        \n",
    "        \n",
    "    end = time.time()\n",
    "    print(f\"Total time taken: {end - start}\")\n",
    "    timelist.append(end - start)\n",
    "    \n",
    "    df = pd.DataFrame({\"predictions\": predictions, \"ground_truth\": references})\n",
    "    df[\"model_name\"] = model_name\n",
    "    df[\"wer\"] = df.apply(lambda row: wer(row[\"ground_truth\"], row[\"predictions\"]), axis=1)\n",
    "    df[\"cer\"] = df.apply(lambda row: cer(row[\"ground_truth\"], row[\"predictions\"]), axis=1)\n",
    "    df[\"total_time\"] = end-start\n",
    "    \n",
    "    rwer = wer(references, predictions)\n",
    "    rwer = round(100 * rwer, 2)\n",
    "    df[\"total_wer\"] = rwer\n",
    "    werlist.append(rwer)\n",
    "    print(f\"The WER of model: {rwer}\")\n",
    "\n",
    "    rcer = cer(references, predictions)\n",
    "    rcer = round(100 * rcer, 2)\n",
    "    df[\"total_cer\"] = rcer\n",
    "    cerlist.append(rcer)\n",
    "    print(f\"The CER of model: {rcer}\")\n",
    "    \n",
    "    print(f\"The model size is: {get_model_size(whisper_asr.model)}\")\n",
    "    modelsizelist.append(get_model_size(whisper_asr.model))\n",
    "    df[\"model_size\"] = get_model_size(whisper_asr.model)\n",
    "    \n",
    "    save_name = model_name.split(\"/\")\n",
    "    print(save_name)\n",
    "    df.to_parquet(f\"/home/msc_results/{save_name[0]}_{save_name[1]}_msc.parquet\")\n",
    "    \n",
    "    clear_gpu_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0ec3af-1ea7-44a3-8776-fa2bac7cf414",
   "metadata": {},
   "source": [
    "## Testing with a sample model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889a10d4-0106-4c77-ab10-f9c0402e0f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/.cache/huggingface/datasets/thennal___parquet/thennal--msc-cc9d10989b2ac4bd/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /home/.cache/huggingface/datasets/thennal___parquet/thennal--msc-cc9d10989b2ac4bd/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-30f1618974cdefce.arrow\n",
      "Loading cached processed dataset at /home/.cache/huggingface/datasets/thennal___parquet/thennal--msc-cc9d10989b2ac4bd/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-e4f860ca9b159c26.arrow\n",
      "/opt/conda/lib/python3.8/site-packages/transformers/generation_utils.py:1359: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 448 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken: 772.3569941520691\n",
      "The WER of model: 43.95\n",
      "The CER of model: 25.78\n",
      "The model size is: 37.76M\n",
      "['parambharat', 'whisper-tiny-ml']\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "wer_list = []\n",
    "cer_list = []\n",
    "model_size_list = []\n",
    "time_list = []\n",
    "evaluate_whisper_model_msc(\"parambharat/whisper-tiny-ml\", wer_list, cer_list, model_size_list, time_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be46390e-db65-48c7-a089-7f387f13f95e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([43.95], [25.78], [772.3569941520691], ['37.76M'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "wer_list,cer_list, time_list, model_size_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35385c2-bc19-4bdd-a00a-9dca5210f271",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
