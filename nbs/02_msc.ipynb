{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a296e77f-7e61-4016-8d06-cd082a7ce4d9",
   "metadata": {},
   "source": [
    "# Evaluation Malayalam Speech Corpus(MSC) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d24a8420-9224-4b06-9bd0-bf39f5e9da47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp msc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47329ad1-4301-4cd4-a02f-8d6f07708e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e71a3422-9b03-490e-a61c-817c57751b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import time\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, Audio\n",
    "from faster_whisper import WhisperModel\n",
    "from jiwer import wer, cer\n",
    "from transformers import pipeline\n",
    "from tqdm.notebook import tqdm\n",
    "from whisper_normalizer.malayalam import MalayalamTextNormalizer\n",
    "\n",
    "from malayalam_asr_benchmarking.utils import is_target_text_in_range, get_text, data, get_model_size, clear_gpu_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8256347b-c03b-462c-9072-be56e005fd95",
   "metadata": {},
   "source": [
    "## Loading dataset and evaluating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f93bf399-397b-424a-8284-c9719ebd15a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_malayalam_speech_corpus_dataset():\n",
    "    dataset = load_dataset(\n",
    "            \"thennal/msc\",\n",
    "            split=\"train\"\n",
    "    )\n",
    "    dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "    dataset = dataset.filter(is_target_text_in_range, input_columns=[\"text\"])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e1db601-1cf3-4d50-a9be-26e919e2576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "normalizer = MalayalamTextNormalizer()\n",
    "def evaluate_whisper_model_msc(\n",
    "        model_name: str, # The model name\n",
    "        werlist: List[float], # WER List\n",
    "        cerlist: List[float], # CER list\n",
    "        modelsizelist: List[str], # model size list\n",
    "        timelist: List[float], # time(s) list\n",
    "        bs:int =16, # batch size\n",
    ")->None:\n",
    "    whisper_asr = pipeline(\n",
    "            \"automatic-speech-recognition\", model=model_name, device=0\n",
    "        )\n",
    "    dataset = load_malayalam_speech_corpus_dataset()\n",
    "    \n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"process of calculating predictions\")\n",
    "    for out in tqdm(whisper_asr(data(dataset), batch_size=bs)):\n",
    "        predictions.append(normalizer(out[\"text\"]))\n",
    "        references.append(normalizer(out[\"reference\"][0]))\n",
    "        \n",
    "    print(\"completed getting predictions\")\n",
    "    end = time.time()\n",
    "    print(f\"Total time taken: {end - start}\")\n",
    "    timelist.append(end - start)\n",
    "    \n",
    "    df = pd.DataFrame({\"predictions\": predictions, \"ground_truth\": references})\n",
    "    df[\"model_name\"] = model_name\n",
    "    df[\"wer\"] = df.apply(lambda row: wer(normalizer(row[\"ground_truth\"]), normalizer(row[\"predictions\"])), axis=1)\n",
    "    df[\"cer\"] = df.apply(lambda row: cer(normalizer(row[\"ground_truth\"]), normalizer(row[\"predictions\"])), axis=1)\n",
    "    df[\"total_time\"] = end-start\n",
    "    \n",
    "    rwer = wer(references, predictions)\n",
    "    rwer = round(100 * rwer, 2)\n",
    "    df[\"total_wer\"] = rwer\n",
    "    werlist.append(rwer)\n",
    "    print(f\"The WER of model: {rwer}\")\n",
    "\n",
    "    rcer = cer(references, predictions)\n",
    "    rcer = round(100 * rcer, 2)\n",
    "    df[\"total_cer\"] = rcer\n",
    "    cerlist.append(rcer)\n",
    "    print(f\"The CER of model: {rcer}\")\n",
    "    \n",
    "    print(f\"The model size is: {get_model_size(whisper_asr.model)}\")\n",
    "    modelsizelist.append(get_model_size(whisper_asr.model))\n",
    "    df[\"model_size\"] = get_model_size(whisper_asr.model)\n",
    "    \n",
    "    save_name = model_name.split(\"/\")\n",
    "    print(save_name)\n",
    "    df.to_parquet(f\"{save_name[0]}_{save_name[1]}_msc.parquet\")\n",
    "    \n",
    "    clear_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "060445d3-26c0-45e3-b984-f3eed06925fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kurianbenoy/malayalam_asr_benchmarking/blob/main/malayalam_asr_benchmarking/msc.py#L38){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### evaluate_whisper_model_msc\n",
       "\n",
       ">      evaluate_whisper_model_msc (model_name:str, werlist:List[float],\n",
       ">                                  cerlist:List[float], modelsizelist:List[str],\n",
       ">                                  timelist:List[float], bs:int=16)\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| model_name | str |  | The model name |\n",
       "| werlist | List |  | WER List |\n",
       "| cerlist | List |  | CER list |\n",
       "| modelsizelist | List |  | model size list |\n",
       "| timelist | List |  | time(s) list |\n",
       "| bs | int | 16 | batch size |\n",
       "| **Returns** | **None** |  |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kurianbenoy/malayalam_asr_benchmarking/blob/main/malayalam_asr_benchmarking/msc.py#L38){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### evaluate_whisper_model_msc\n",
       "\n",
       ">      evaluate_whisper_model_msc (model_name:str, werlist:List[float],\n",
       ">                                  cerlist:List[float], modelsizelist:List[str],\n",
       ">                                  timelist:List[float], bs:int=16)\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| model_name | str |  | The model name |\n",
       "| werlist | List |  | WER List |\n",
       "| cerlist | List |  | CER list |\n",
       "| modelsizelist | List |  | model size list |\n",
       "| timelist | List |  | time(s) list |\n",
       "| bs | int | 16 | batch size |\n",
       "| **Returns** | **None** |  |  |"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(evaluate_whisper_model_msc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0ec3af-1ea7-44a3-8776-fa2bac7cf414",
   "metadata": {},
   "source": [
    "## Testing with a sample model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4b4e0f-a719-44f0-850a-45c9747f5d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "wer_list = []\n",
    "cer_list = []\n",
    "model_size_list = []\n",
    "time_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1819a065-951c-4686-8337-dc097837bb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/.cache/huggingface/datasets/thennal___parquet/thennal--msc-cc9d10989b2ac4bd/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /home/.cache/huggingface/datasets/thennal___parquet/thennal--msc-cc9d10989b2ac4bd/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-30f1618974cdefce.arrow\n",
      "Loading cached processed dataset at /home/.cache/huggingface/datasets/thennal___parquet/thennal--msc-cc9d10989b2ac4bd/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-e4f860ca9b159c26.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process of calculating predictions\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.035051584243774414,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "523b48e7ee31401aabb6a5292e82f3d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/generation_utils.py:1359: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 448 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed getting predictions\n",
      "Total time taken: 375.53221249580383\n",
      "The WER of model: 139.63\n",
      "The CER of model: 177.3\n",
      "The model size is: 37.76M\n",
      "['openai', 'whisper-tiny']\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "evaluate_whisper_model_msc(\"openai/whisper-tiny\", wer_list, cer_list, model_size_list, time_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b0ad44-642e-435d-bc0a-311428bb0e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/.cache/huggingface/datasets/thennal___parquet/thennal--msc-cc9d10989b2ac4bd/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /home/.cache/huggingface/datasets/thennal___parquet/thennal--msc-cc9d10989b2ac4bd/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-30f1618974cdefce.arrow\n",
      "Loading cached processed dataset at /home/.cache/huggingface/datasets/thennal___parquet/thennal--msc-cc9d10989b2ac4bd/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-e4f860ca9b159c26.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process of calculating predictions\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02561211585998535,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf188dfdbc514f10ab44c36bcc62439c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/generation_utils.py:1359: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 448 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed getting predictions\n",
      "Total time taken: 448.9504859447479\n",
      "The WER of model: 155.97\n",
      "The CER of model: 200.05\n",
      "The model size is: 72.59M\n",
      "['openai', 'whisper-base']\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "evaluate_whisper_model_msc(\"openai/whisper-base\", wer_list, cer_list, model_size_list, time_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda174f8-194d-423d-98ec-b36a3632aaa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/.cache/huggingface/datasets/thennal___parquet/thennal--msc-cc9d10989b2ac4bd/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /home/.cache/huggingface/datasets/thennal___parquet/thennal--msc-cc9d10989b2ac4bd/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-30f1618974cdefce.arrow\n",
      "Loading cached processed dataset at /home/.cache/huggingface/datasets/thennal___parquet/thennal--msc-cc9d10989b2ac4bd/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-e4f860ca9b159c26.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process of calculating predictions\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.025384902954101562,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6e288ffcf5b4b89a2ef2fca5e233e2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/generation_utils.py:1359: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 448 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed getting predictions\n",
      "Total time taken: 479.73656272888184\n",
      "The WER of model: 111.57\n",
      "The CER of model: 123.7\n",
      "The model size is: 241.73M\n",
      "['openai', 'whisper-small']\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "evaluate_whisper_model_msc(\"openai/whisper-small\", wer_list, cer_list, model_size_list, time_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feebb02-e691-43a6-a7ca-f59bbbfcab66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/.cache/huggingface/datasets/thennal___parquet/thennal--msc-cc9d10989b2ac4bd/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /home/.cache/huggingface/datasets/thennal___parquet/thennal--msc-cc9d10989b2ac4bd/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-30f1618974cdefce.arrow\n",
      "Loading cached processed dataset at /home/.cache/huggingface/datasets/thennal___parquet/thennal--msc-cc9d10989b2ac4bd/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-e4f860ca9b159c26.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process of calculating predictions\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.026051998138427734,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0ede997357b428d9b8a5d6393a249a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/generation_utils.py:1359: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 448 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed getting predictions\n",
      "Total time taken: 10467.876322746277\n",
      "The WER of model: 23.57\n",
      "The CER of model: 12.33\n",
      "The model size is: 1.54B\n",
      "['anuragshas', 'whisper-large-v2-ml']\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "evaluate_whisper_model_msc(\"anuragshas/whisper-large-v2-ml\", wer_list, cer_list, model_size_list, time_list, bs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35385c2-bc19-4bdd-a00a-9dca5210f271",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/.cache/huggingface/datasets/thennal___parquet/thennal--msc-cc9d10989b2ac4bd/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /home/.cache/huggingface/datasets/thennal___parquet/thennal--msc-cc9d10989b2ac4bd/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-30f1618974cdefce.arrow\n",
      "Loading cached processed dataset at /home/.cache/huggingface/datasets/thennal___parquet/thennal--msc-cc9d10989b2ac4bd/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-e4f860ca9b159c26.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process of calculating predictions\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.03333234786987305,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "589573d397c649cdbd8a98fd596e4e05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/generation_utils.py:1359: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 448 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "evaluate_whisper_model_msc(\"DrishtiSharma/whisper-large-v2-malayalam\", wer_list, cer_list, model_size_list, time_list, bs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce1a5da-3c2f-40b7-adb9-a0f482d9f2ad",
   "metadata": {},
   "source": [
    "### Faster-whisper models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6b4fcd0-bb2f-4512-b7c9-c364abe635f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'speechid': '0I2iIh7OSMdWhvb85tMp',\n",
       " 'speaker_id': 'oeaNxrE0uxNSfoDpdrCYGBGC7uC3',\n",
       " 'review_score': 42,\n",
       " 'transcript': 'അണ്ണാൻ മൂത്താലും മരം കേറ്റം മറക്കുമോ?',\n",
       " 'category': 'proverb',\n",
       " 'speaker_gender': 'default',\n",
       " 'speaker_age': 'default',\n",
       " 'audio': {'path': None,\n",
       "  'array': array([-1.16415322e-10, -5.82076609e-11,  0.00000000e+00, ...,\n",
       "         -3.16558471e-05, -2.90179141e-05, -3.30671537e-05]),\n",
       "  'sampling_rate': 16000},\n",
       " 'norm_text': 'അണ ണ ൻ മ ത ത ല മര ക റ റ മറക ക മ '}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "dataset = load_malayalam_speech_corpus_dataset()\n",
    "t = dataset[0]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7bf2ee90-a790-4f3c-9779-696d8d343420",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def evaluate_faster_whisper_model_msc(\n",
    "        model_name: str, # The model name\n",
    "        werlist: List[float], # WER List\n",
    "        cerlist: List[float],# CER list\n",
    "        modelsizelist: List[str], # model size list\n",
    "        timelist: List[float], # time(s) list\n",
    "        bs:int =16, # batch size. Default value is 16.\n",
    "        compute_type:str=\"float16\", # The compute type supported by faster-Whisper\n",
    "        beam_size=1, # beam size\n",
    ")->None:\n",
    "    \"\"\"A utility function for calculing WER in Common voice dataset provided a model name in huggingface.\n",
    "       You can store a WER, CER, ModelSize, TimeList to calculate results cumulatively over different epochs\n",
    "    \"\"\"\n",
    "    dataset = load_malayalam_speech_corpus_dataset()\n",
    "    model = WhisperModel(model_name, device=\"cuda\", compute_type=compute_type)\n",
    "     \n",
    "    \n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    start = time.time()\n",
    "    for x in tqdm(dataset):\n",
    "        segments, info = model.transcribe(x[\"audio\"][\"array\"], beam_size=beam_size)\n",
    "        predictions.append(normalizer(\" \".join([segment.text for segment in segments])))\n",
    "        references.append(normalizer(x[\"transcript\"]))\n",
    "              \n",
    "    end = time.time()\n",
    "    print(f\"Total time taken: {end - start}\")\n",
    "    timelist.append(end - start)\n",
    "    \n",
    "    df = pd.DataFrame({\"predictions\": predictions, \"ground_truth\": references})\n",
    "    df[\"model_name\"] = model_name\n",
    "    df[\"wer\"] = df.apply(lambda row: wer(normalizer(row[\"ground_truth\"]), normalizer(row[\"predictions\"])), axis=1)\n",
    "    df[\"cer\"] = df.apply(lambda row: cer(normalizer(row[\"ground_truth\"]), normalizer(row[\"predictions\"])), axis=1)\n",
    "    df[\"total_time\"] = end-start\n",
    "    \n",
    "    rwer = wer(references, predictions)\n",
    "    rwer = round(100 * rwer, 2)\n",
    "    werlist.append(rwer)\n",
    "    print(f\"The WER of model: {rwer}\")\n",
    "\n",
    "    rcer = cer(references, predictions)\n",
    "    rcer = round(100 * rcer, 2)\n",
    "    cerlist.append(rcer)\n",
    "    print(f\"The CER of model: {rcer}\")\n",
    "    \n",
    "    # print(f\"The model size is: {get_model_size(whisper_asr.model)}\")\n",
    "    # modelsizelist.append(get_model_size(whisper_asr.model))\n",
    "    # df[\"model_size\"] = get_model_size(whisper_asr.model)\n",
    "    \n",
    "    save_name = model_name.split(\"/\")\n",
    "    print(save_name)\n",
    "    df.to_parquet(f\"{save_name[0]}_{save_name[1]}_msc.parquet\")\n",
    "    \n",
    "    clear_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8bf657f4-2c47-4803-9ba8-3247888b1cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6540c0da9a14eb98b4651f09fde78b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1541 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken: 1052.7706644535065\n",
      "The WER of model: 11.66\n",
      "The CER of model: 10.27\n",
      "['kurianbenoy', 'vegam-whisper-medium-ml-fp16']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([11.66], [10.27], [], [1052.7706644535065])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "wer_list = []\n",
    "cer_list = []\n",
    "model_size_list = []\n",
    "time_list = []\n",
    "evaluate_faster_whisper_model_msc(\"kurianbenoy/vegam-whisper-medium-ml-fp16\", wer_list, cer_list, model_size_list, time_list)\n",
    "wer_list, cer_list, model_size_list, time_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaed816-6b8b-40d2-b90b-cdd3a9a4a7cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
