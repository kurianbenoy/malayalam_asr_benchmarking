{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Utilities\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "# from transformers.models.whisper.english_normalizer import BasicTextNormalizer\n",
    "from numerize import numerize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# whisper_norm = BasicTextNormalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def is_target_text_in_range(ref):\n",
    "    if ref.strip() == \"ignore time segment in scoring\":\n",
    "        return False\n",
    "    else:\n",
    "        return ref.strip() != \"\"\n",
    "\n",
    "\n",
    "def get_text(sample):\n",
    "    if \"text\" in sample:\n",
    "        return sample[\"text\"]\n",
    "    elif \"sentence\" in sample:\n",
    "        return sample[\"sentence\"]\n",
    "    elif \"normalized_text\" in sample:\n",
    "        return sample[\"normalized_text\"]\n",
    "    elif \"transcript\" in sample:\n",
    "        return sample[\"transcript\"]\n",
    "    elif \"transcription\" in sample:\n",
    "        return sample[\"transcription\"]\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Expected transcript column of either 'text', 'sentence', 'normalized_text' or 'transcript'. Got sample of \"\n",
    "            \".join{sample.keys()}. Ensure a text column name is present in the dataset.\"\n",
    "        )\n",
    "        \n",
    "# def normalise(batch):\n",
    "#     batch[\"norm_text\"] = whisper_norm(get_text(batch))\n",
    "#     return batch\n",
    "\n",
    "\n",
    "def data(dataset):\n",
    "    for i, item in enumerate(dataset):\n",
    "        yield {**item[\"audio\"], \"reference\": item[\"norm_text\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_model_size(model):\n",
    "    total_params = sum(param.numel() for param in model.parameters())\n",
    "    return numerize.numerize(total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def clear_gpu_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def store_results_as_dataset(predictions, predictions_raw, references, reference_raw, model_name, time, model_size, wer, cer,saving_name):\n",
    "    df = pd.DataFrame({\"predictions\": predictions, \"ground_truth\": references, \"prediction_raw\": predictions_raw, \"references_raw\": references_raw, \"model_name\": model_name})\n",
    "    df[\"wer\"] = df.apply(lambda row: wer(row[\"ground_truth\"], row[\"predictions\"]), axis=1)\n",
    "    df[\"cer\"] = df.apply(lambda row: cer(row[\"ground_truth\"], row[\"predictions\"]), axis=1)\n",
    "\n",
    "    df[\"total_time\"] = time\n",
    "    df[\"model_size\"] = model_size\n",
    "    df[\"total_wer\"] = wer\n",
    "    df[\"total_cer\"] = cer\n",
    "\n",
    "    save_name = model_name.split(\"/\")\n",
    "    save_name += saving_name\n",
    "    df.to_parquet(save_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
