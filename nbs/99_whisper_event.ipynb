{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae3a9226-e4c0-4c17-92b7-f009d1647d5c",
   "metadata": {},
   "source": [
    "# Benchmarking Results in Malayalam datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc0cf1b-2723-425d-94b4-179cb3954ec0",
   "metadata": {},
   "source": [
    "## Whisper-Event Leaderboard\n",
    "\n",
    "[HuggingFace Team](huggingface.co/) conducted a whisper event on fine tuning Whisper model to achieve the State of the art results performance for various languages.\n",
    "\n",
    "During this competitions lot of models where evaluated on dataset like [Common Voice](https://huggingface.co/datasets/mozilla-foundation/common_voice_11_0). \n",
    "\n",
    "For the language Malayalam, the results are as follows in Common Voice dataset subsection of Malayalam:\n",
    "\n",
    "![Results in common voice](https://user-images.githubusercontent.com/24592806/222974236-44f047ec-e072-4f6a-b49f-ed88afb02999.png)\n",
    "\n",
    "There was an evaluation in Google Fluers Malaylam subsection as well:\n",
    "\n",
    "![Results in Fluers](https://user-images.githubusercontent.com/24592806/222974253-0fb96dd3-64ae-4ea2-a022-fd3db35cf721.png)\n",
    "\n",
    "\n",
    "[Details are from Huggingface whisper-event leaderboard](https://huggingface.co/spaces/whisper-event/leaderboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e932cc72-95e8-44a4-8e1a-0d679555edc0",
   "metadata": {},
   "source": [
    "## Benchmarking in Common Voice Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8f170c-69c3-42f6-947e-e467db5a5f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from malayalam_asr_benchmarking.commonvoice import evaluate_whisper_model_common_voice "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef61462-f10b-4532-914f-b6af0522eb49",
   "metadata": {},
   "source": [
    "**ASR models to benchmark**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39944612-fab0-4ebd-9173-60dece858544",
   "metadata": {},
   "outputs": [],
   "source": [
    "asr_models = [\"thennal/whisper-medium-ml\",\n",
    "              \"anuragshas/whisper-large-v2-ml\",\n",
    "              \"parambharat/whisper-small-ml\",\n",
    "              \"DrishtiSharma/whisper-large-v2-malayalam\",\n",
    "              \"parambharat/whisper-base-ml\",\n",
    "              \"kurianbenoy/whisper_malayalam_largev2\",\n",
    "              \"parambharat/whisper-tiny-ml\"\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05993394-ca7d-4709-ac0e-ce2350ff9c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'parambharat/whisper-tiny-ml'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asr_models[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939d152e-3caf-440a-8b99-500d1a0a5655",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset common_voice_11_0 (/home/.cache/huggingface/datasets/mozilla-foundation___common_voice_11_0/ml/11.0.0/2c65b95d99ca879b1b1074ea197b65e0497848fd697fdb0582e0f6b75b6f4da0)\n",
      "Loading cached processed dataset at /home/.cache/huggingface/datasets/mozilla-foundation___common_voice_11_0/ml/11.0.0/2c65b95d99ca879b1b1074ea197b65e0497848fd697fdb0582e0f6b75b6f4da0/cache-374585c2877047e3.arrow\n",
      "Loading cached processed dataset at /home/.cache/huggingface/datasets/mozilla-foundation___common_voice_11_0/ml/11.0.0/2c65b95d99ca879b1b1074ea197b65e0497848fd697fdb0582e0f6b75b6f4da0/cache-22670505c562e0d4.arrow\n",
      "/opt/conda/lib/python3.8/site-packages/transformers/generation_utils.py:1359: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 448 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken: 84.1298975944519\n",
      "The WER of model: 38.31\n",
      "The CER of model: 21.93\n",
      "The model size is: 37.76M\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "evaluate_whisper_model_common_voice(asr_models[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8eb95a-ed63-40d4-aee8-5adf22574eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.033968448638916016,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 1032,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6317794a5bd434996f689dfff71746c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.03k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.03279399871826172,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 3055754841,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df487fb286494d68841745aa28e215ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.06G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.032654523849487305,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 830,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f707574fc2004ac081e31608df917c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/830 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.031210660934448242,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 1036558,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59fef3b5c00749f4bbacb28f5423ffae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.030309438705444336,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 493864,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc1765ff6bd04c60847a50812f7f5fc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/494k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.033006906509399414,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 52666,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e7607f40f4543eeae6c4e10c742ae83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/52.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.032109975814819336,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 2108,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76821b9f87f4423c8602e8dd0699e0ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.11k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.03263664245605469,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 2064,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "831d76918ce8441684e38950f8504c0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.06k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.032950639724731445,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 184990,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c02e2b950ee440a68896f353c05bcd42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/185k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset common_voice_11_0 (/home/.cache/huggingface/datasets/mozilla-foundation___common_voice_11_0/ml/11.0.0/2c65b95d99ca879b1b1074ea197b65e0497848fd697fdb0582e0f6b75b6f4da0)\n",
      "Loading cached processed dataset at /home/.cache/huggingface/datasets/mozilla-foundation___common_voice_11_0/ml/11.0.0/2c65b95d99ca879b1b1074ea197b65e0497848fd697fdb0582e0f6b75b6f4da0/cache-374585c2877047e3.arrow\n",
      "Loading cached processed dataset at /home/.cache/huggingface/datasets/mozilla-foundation___common_voice_11_0/ml/11.0.0/2c65b95d99ca879b1b1074ea197b65e0497848fd697fdb0582e0f6b75b6f4da0/cache-22670505c562e0d4.arrow\n",
      "/opt/conda/lib/python3.8/site-packages/transformers/generation_utils.py:1359: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 448 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken: 1086.15980052948\n",
      "The WER of model: 11.56\n",
      "The CER of model: 5.41\n",
      "The model size is: 763.86M\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "evaluate_whisper_model_common_voice(asr_models[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b21dad-1e28-4c02-a6e2-8d515f43595b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/.cache/huggingface/hub/models--anuragshas--whisper-large-v2-ml/refs/main'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#|eval: false\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mevaluate_whisper_model_common_voice\u001b[49m\u001b[43m(\u001b[49m\u001b[43masr_models\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/malayalam_asr_benchmarking/malayalam_asr_benchmarking/commonvoice.py:26\u001b[0m, in \u001b[0;36mevaluate_whisper_model_common_voice\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_whisper_model_common_voice\u001b[39m(model_name: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 26\u001b[0m     whisper_asr \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mautomatic-speech-recognition\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmozilla-foundation/common_voice_11_0\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mml\u001b[39m\u001b[38;5;124m\"\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mcast_column(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m, Audio(sampling_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16000\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/pipelines/__init__.py:648\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    646\u001b[0m     hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39m_commit_hash\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 648\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[43mAutoConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_from_pipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    649\u001b[0m     hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39m_commit_hash\n\u001b[1;32m    651\u001b[0m custom_tasks \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py:776\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname_or_path\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pretrained_model_name_or_path\n\u001b[1;32m    775\u001b[0m trust_remote_code \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust_remote_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 776\u001b[0m config_dict, unused_kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mPretrainedConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m trust_remote_code:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/configuration_utils.py:559\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    557\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    558\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 559\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n\u001b[1;32m    561\u001b[0m     original_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/configuration_utils.py:614\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m configuration_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_configuration_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, CONFIG_NAME)\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    613\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 614\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    628\u001b[0m     commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;66;03m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001b[39;00m\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# the original exception.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/utils/hub.py:409\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    406\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m http_user_agent(user_agent)\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 409\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError:\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    425\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    426\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    427\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpass a token having permission to this repo with `use_auth_token` or log in with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    428\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`huggingface-cli login` and pass `use_auth_token=True`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    429\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:124\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    120\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(\n\u001b[1;32m    121\u001b[0m         fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs\n\u001b[1;32m    122\u001b[0m     )\n\u001b[0;32m--> 124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/huggingface_hub/file_download.py:1148\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1147\u001b[0m     ref_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(storage_folder, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrefs\u001b[39m\u001b[38;5;124m\"\u001b[39m, revision)\n\u001b[0;32m-> 1148\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mref_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m   1149\u001b[0m         commit_hash \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1151\u001b[0m pointer_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m   1152\u001b[0m     storage_folder, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msnapshots\u001b[39m\u001b[38;5;124m\"\u001b[39m, commit_hash, relative_filename\n\u001b[1;32m   1153\u001b[0m )\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/.cache/huggingface/hub/models--anuragshas--whisper-large-v2-ml/refs/main'"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "evaluate_whisper_model_common_voice(asr_models[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f4015d-50f7-40c1-a57c-55d771370784",
   "metadata": {},
   "source": [
    "#| hide\n",
    "## How to store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0230db-e1d6-4f78-891d-d9f076dbe5fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_b68c4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Model:</th>\n",
       "      <th id=\"T_b68c4_level0_col0\" class=\"col_heading level0 col0\" colspan=\"2\">Decision Tree</th>\n",
       "      <th id=\"T_b68c4_level0_col2\" class=\"col_heading level0 col2\" colspan=\"2\">Regression</th>\n",
       "      <th id=\"T_b68c4_level0_col4\" class=\"col_heading level0 col4\" colspan=\"2\">Random</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level1\" >Predicted:</th>\n",
       "      <th id=\"T_b68c4_level1_col0\" class=\"col_heading level1 col0\" >Tumour</th>\n",
       "      <th id=\"T_b68c4_level1_col1\" class=\"col_heading level1 col1\" >Non-Tumour</th>\n",
       "      <th id=\"T_b68c4_level1_col2\" class=\"col_heading level1 col2\" >Tumour</th>\n",
       "      <th id=\"T_b68c4_level1_col3\" class=\"col_heading level1 col3\" >Non-Tumour</th>\n",
       "      <th id=\"T_b68c4_level1_col4\" class=\"col_heading level1 col4\" >Tumour</th>\n",
       "      <th id=\"T_b68c4_level1_col5\" class=\"col_heading level1 col5\" >Non-Tumour</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Actual Label:</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b68c4_level0_row0\" class=\"row_heading level0 row0\" >Tumour (Positive)</th>\n",
       "      <td id=\"T_b68c4_row0_col0\" class=\"data row0 col0\" >38.000000</td>\n",
       "      <td id=\"T_b68c4_row0_col1\" class=\"data row0 col1\" >2.000000</td>\n",
       "      <td id=\"T_b68c4_row0_col2\" class=\"data row0 col2\" >18.000000</td>\n",
       "      <td id=\"T_b68c4_row0_col3\" class=\"data row0 col3\" >22.000000</td>\n",
       "      <td id=\"T_b68c4_row0_col4\" class=\"data row0 col4\" >21</td>\n",
       "      <td id=\"T_b68c4_row0_col5\" class=\"data row0 col5\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b68c4_level0_row1\" class=\"row_heading level0 row1\" >Non-Tumour (Negative)</th>\n",
       "      <td id=\"T_b68c4_row1_col0\" class=\"data row1 col0\" >19.000000</td>\n",
       "      <td id=\"T_b68c4_row1_col1\" class=\"data row1 col1\" >439.000000</td>\n",
       "      <td id=\"T_b68c4_row1_col2\" class=\"data row1 col2\" >6.000000</td>\n",
       "      <td id=\"T_b68c4_row1_col3\" class=\"data row1 col3\" >452.000000</td>\n",
       "      <td id=\"T_b68c4_row1_col4\" class=\"data row1 col4\" >226</td>\n",
       "      <td id=\"T_b68c4_row1_col5\" class=\"data row1 col5\" >232.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "\n",
    "df = pd.DataFrame([[38.0, 2.0, 18.0, 22.0, 21, np.nan],[19, 439, 6, 452, 226,232]],\n",
    "                  index=pd.Index(['Tumour (Positive)', 'Non-Tumour (Negative)'], name='Actual Label:'),\n",
    "                  columns=pd.MultiIndex.from_product([['Decision Tree', 'Regression', 'Random'],['Tumour', 'Non-Tumour']], names=['Model:', 'Predicted:']))\n",
    "df.style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c103181-507a-436d-b989-925604677635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_09069\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_09069_level0_col0\" class=\"col_heading level0 col0\" >model_name</th>\n",
       "      <th id=\"T_09069_level0_col1\" class=\"col_heading level0 col1\" >wer</th>\n",
       "      <th id=\"T_09069_level0_col2\" class=\"col_heading level0 col2\" >cer</th>\n",
       "      <th id=\"T_09069_level0_col3\" class=\"col_heading level0 col3\" >time_taken</th>\n",
       "      <th id=\"T_09069_level0_col4\" class=\"col_heading level0 col4\" >model_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_09069_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_09069_row0_col0\" class=\"data row0 col0\" >thennal/whisper-medium-ml</td>\n",
       "      <td id=\"T_09069_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "      <td id=\"T_09069_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "      <td id=\"T_09069_row0_col3\" class=\"data row0 col3\" >0</td>\n",
       "      <td id=\"T_09069_row0_col4\" class=\"data row0 col4\" >1M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_09069_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_09069_row1_col0\" class=\"data row1 col0\" >anuragshas/whisper-large-v2-ml</td>\n",
       "      <td id=\"T_09069_row1_col1\" class=\"data row1 col1\" >0</td>\n",
       "      <td id=\"T_09069_row1_col2\" class=\"data row1 col2\" >0</td>\n",
       "      <td id=\"T_09069_row1_col3\" class=\"data row1 col3\" >0</td>\n",
       "      <td id=\"T_09069_row1_col4\" class=\"data row1 col4\" >1M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_09069_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_09069_row2_col0\" class=\"data row2 col0\" >parambharat/whisper-small-ml</td>\n",
       "      <td id=\"T_09069_row2_col1\" class=\"data row2 col1\" >0</td>\n",
       "      <td id=\"T_09069_row2_col2\" class=\"data row2 col2\" >0</td>\n",
       "      <td id=\"T_09069_row2_col3\" class=\"data row2 col3\" >0</td>\n",
       "      <td id=\"T_09069_row2_col4\" class=\"data row2 col4\" >1M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_09069_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_09069_row3_col0\" class=\"data row3 col0\" >DrishtiSharma/whisper-large-v2-malayalam</td>\n",
       "      <td id=\"T_09069_row3_col1\" class=\"data row3 col1\" >0</td>\n",
       "      <td id=\"T_09069_row3_col2\" class=\"data row3 col2\" >0</td>\n",
       "      <td id=\"T_09069_row3_col3\" class=\"data row3 col3\" >0</td>\n",
       "      <td id=\"T_09069_row3_col4\" class=\"data row3 col4\" >1M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_09069_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_09069_row4_col0\" class=\"data row4 col0\" >parambharat/whisper-base-ml</td>\n",
       "      <td id=\"T_09069_row4_col1\" class=\"data row4 col1\" >0</td>\n",
       "      <td id=\"T_09069_row4_col2\" class=\"data row4 col2\" >0</td>\n",
       "      <td id=\"T_09069_row4_col3\" class=\"data row4 col3\" >0</td>\n",
       "      <td id=\"T_09069_row4_col4\" class=\"data row4 col4\" >1M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_09069_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_09069_row5_col0\" class=\"data row5 col0\" >kurianbenoy/whisper_malayalam_largev2</td>\n",
       "      <td id=\"T_09069_row5_col1\" class=\"data row5 col1\" >0</td>\n",
       "      <td id=\"T_09069_row5_col2\" class=\"data row5 col2\" >0</td>\n",
       "      <td id=\"T_09069_row5_col3\" class=\"data row5 col3\" >0</td>\n",
       "      <td id=\"T_09069_row5_col4\" class=\"data row5 col4\" >1M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_09069_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_09069_row6_col0\" class=\"data row6 col0\" >parambharat/whisper-tiny-ml</td>\n",
       "      <td id=\"T_09069_row6_col1\" class=\"data row6 col1\" >0</td>\n",
       "      <td id=\"T_09069_row6_col2\" class=\"data row6 col2\" >0</td>\n",
       "      <td id=\"T_09069_row6_col3\" class=\"data row6 col3\" >0</td>\n",
       "      <td id=\"T_09069_row6_col4\" class=\"data row6 col4\" >1M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.style.format(precision=0, na_rep='MISSING', thousands=\" \",\n",
    "                formatter={('Decision Tree', 'Tumour'): \"{:.2f}\",\n",
    "                           ('Regression', 'Non-Tumour'): lambda x: \"$ {:,.1f}\".format(x*-1e6)\n",
    "                          })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f399ca1a-dcc9-48e5-826d-4cddde719d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>wer</th>\n",
       "      <th>cer</th>\n",
       "      <th>time_taken</th>\n",
       "      <th>model_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thennal/whisper-medium-ml</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anuragshas/whisper-large-v2-ml</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>parambharat/whisper-small-ml</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DrishtiSharma/whisper-large-v2-malayalam</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>parambharat/whisper-base-ml</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model_name  wer  cer  time_taken model_size\n",
       "0                 thennal/whisper-medium-ml    0    0           0         1M\n",
       "1            anuragshas/whisper-large-v2-ml    0    0           0         1M\n",
       "2              parambharat/whisper-small-ml    0    0           0         1M\n",
       "3  DrishtiSharma/whisper-large-v2-malayalam    0    0           0         1M\n",
       "4               parambharat/whisper-base-ml    0    0           0         1M"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "df =pd.DataFrame({\"model_name\": asr_models})\n",
    "\n",
    "df[\"wer\"] = 0\n",
    "df[\"cer\"] = 0\n",
    "df[\"time_taken\"] = 0\n",
    "df[\"model_size\"] = \"1M\"\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b1c3d6-fce1-42cf-b7c8-1fa5c3cd91d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
