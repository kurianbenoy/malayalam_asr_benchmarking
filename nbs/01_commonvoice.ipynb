{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d381ea18-77f9-4749-8411-426aeacec856",
   "metadata": {},
   "source": [
    "# Evaluation Common Voice - malayalam subset dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad7f4a0c-5038-4be1-b569-94a8c5b51827",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp commonvoice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae4ce661-cbba-48f1-86a2-e6f68ff800fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3f6bcbd-7707-442b-81d0-1bc7f0d058d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (616949157.py, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    from whisper_normalizer.malayalam import\u001b[0m\n\u001b[0m                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import time\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, Audio\n",
    "from faster_whisper import WhisperModel\n",
    "from jiwer import wer, cer\n",
    "from transformers import pipeline\n",
    "from tqdm.notebook import tqdm\n",
    "from whisper_normalizer.malayalam import MalayalamTextNormalizer\n",
    "\n",
    "from malayalam_asr_benchmarking.utils import is_target_text_in_range, get_text, data, get_model_size, clear_gpu_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "798e1946",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_common_voice_malayalam_dataset():\n",
    "    dataset = load_dataset(\n",
    "            \"mozilla-foundation/common_voice_11_0\",\n",
    "            \"ml\",\n",
    "            split=\"test\"\n",
    "    )\n",
    "    dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "    dataset = dataset.filter(is_target_text_in_range, input_columns=[\"norm_text\"])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a01fed8-025a-4320-a00e-116b3a9fb0fa",
   "metadata": {},
   "source": [
    "### Transformer Whisper models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c48f20f-b900-438d-ae89-3067d9166167",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "normalizer = MalayalamTextNormalizer()\n",
    "def evaluate_whisper_model_common_voice(\n",
    "        model_name: str, # The model name\n",
    "        werlist: List[float], # WER List\n",
    "        cerlist: List[float],# CER list\n",
    "        modelsizelist: List[str], # model size list\n",
    "        timelist: List[float], # time(s) list\n",
    "        bs:int =16, # batch size. Default value is 16.\n",
    ")->None:\n",
    "    \"\"\"A utility function for calculing WER in Common voice dataset provided a model name in huggingface.\n",
    "       You can store a WER, CER, ModelSize, TimeList to calculate results cumulatively over different epochs\n",
    "    \"\"\"\n",
    "    whisper_asr = pipeline(\n",
    "            \"automatic-speech-recognition\", model=model_name, device=0\n",
    "        )\n",
    "    dataset = load_common_voice_malayalam_dataset()\n",
    "\n",
    "    prediction_raw = []\n",
    "    references_raw = []\n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    start = time.time()\n",
    "    for out in whisper_asr(data(dataset), batch_size=bs):\n",
    "        prediction_raw.append(out[\"text\"])\n",
    "        references_raw.append(out[\"reference\"][0])\n",
    "        predictions.append(normalizer((out[\"text\"])))\n",
    "        references.append(normalizer(out[\"reference\"][0]))\n",
    "        \n",
    "        \n",
    "    end = time.time()\n",
    "    print(f\"Total time taken: {end - start}\")\n",
    "    timelist.append(end - start)\n",
    "    \n",
    "    df = pd.DataFrame({\"predictions\": predictions, \"ground_truth\": references})\n",
    "    df[\"model_name\"] = model_name\n",
    "    df[\"wer\"] = df.apply(lambda row: wer(normalizer(row[\"ground_truth\"]), normalizer(row[\"predictions\"])), axis=1)\n",
    "    df[\"cer\"] = df.apply(lambda row: cer(normalizer(row[\"ground_truth\"]), normalizer(row[\"predictions\"])), axis=1)\n",
    "    df[\"total_time\"] = end-start\n",
    "    \n",
    "    rwer = wer(references, predictions)\n",
    "    rwer = round(100 * rwer, 2)\n",
    "    werlist.append(rwer)\n",
    "    print(f\"The WER of model: {rwer}\")\n",
    "\n",
    "    rcer = cer(references, predictions)\n",
    "    rcer = round(100 * rcer, 2)\n",
    "    cerlist.append(rcer)\n",
    "    print(f\"The CER of model: {rcer}\")\n",
    "    \n",
    "    print(f\"The model size is: {get_model_size(whisper_asr.model)}\")\n",
    "    modelsizelist.append(get_model_size(whisper_asr.model))\n",
    "    df[\"model_size\"] = get_model_size(whisper_asr.model)\n",
    "    \n",
    "    save_name = model_name.split(\"/\")\n",
    "    print(save_name)\n",
    "    df.to_parquet(f\"{save_name[0]}_{save_name[1]}_commonvoice.parquet\")\n",
    "    \n",
    "    clear_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77b58b5a-d5ce-4efb-8eda-1a2438cca98e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kurianbenoy/malayalam_asr_benchmarking/blob/main/malayalam_asr_benchmarking/commonvoice.py#L38){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### evaluate_whisper_model_common_voice\n",
       "\n",
       ">      evaluate_whisper_model_common_voice (model_name:str, werlist:List[float],\n",
       ">                                           cerlist:List[float],\n",
       ">                                           modelsizelist:List[str],\n",
       ">                                           timelist:List[float], bs:int=16)\n",
       "\n",
       "A utility function for calculing WER in Common voice dataset provided a model name in huggingface.\n",
       "You can store a WER, CER, ModelSize, TimeList to calculate results cumulatively over different epochs\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| model_name | str |  | The model name |\n",
       "| werlist | List |  | WER List |\n",
       "| cerlist | List |  | CER list |\n",
       "| modelsizelist | List |  | model size list |\n",
       "| timelist | List |  | time(s) list |\n",
       "| bs | int | 16 | batch size. Default value is 16. |\n",
       "| **Returns** | **None** |  |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kurianbenoy/malayalam_asr_benchmarking/blob/main/malayalam_asr_benchmarking/commonvoice.py#L38){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### evaluate_whisper_model_common_voice\n",
       "\n",
       ">      evaluate_whisper_model_common_voice (model_name:str, werlist:List[float],\n",
       ">                                           cerlist:List[float],\n",
       ">                                           modelsizelist:List[str],\n",
       ">                                           timelist:List[float], bs:int=16)\n",
       "\n",
       "A utility function for calculing WER in Common voice dataset provided a model name in huggingface.\n",
       "You can store a WER, CER, ModelSize, TimeList to calculate results cumulatively over different epochs\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| model_name | str |  | The model name |\n",
       "| werlist | List |  | WER List |\n",
       "| cerlist | List |  | CER list |\n",
       "| modelsizelist | List |  | model size list |\n",
       "| timelist | List |  | time(s) list |\n",
       "| bs | int | 16 | batch size. Default value is 16. |\n",
       "| **Returns** | **None** |  |  |"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(evaluate_whisper_model_common_voice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecebe2cc-e590-4b39-aa30-a2d317db72d8",
   "metadata": {},
   "source": [
    "## Testing with a sample model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c2f808-0803-4c54-9bd7-f4df36ab7228",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset common_voice_11_0 (/home/.cache/huggingface/datasets/mozilla-foundation___common_voice_11_0/ml/11.0.0/2c65b95d99ca879b1b1074ea197b65e0497848fd697fdb0582e0f6b75b6f4da0)\n",
      "Loading cached processed dataset at /home/.cache/huggingface/datasets/mozilla-foundation___common_voice_11_0/ml/11.0.0/2c65b95d99ca879b1b1074ea197b65e0497848fd697fdb0582e0f6b75b6f4da0/cache-374585c2877047e3.arrow\n",
      "Loading cached processed dataset at /home/.cache/huggingface/datasets/mozilla-foundation___common_voice_11_0/ml/11.0.0/2c65b95d99ca879b1b1074ea197b65e0497848fd697fdb0582e0f6b75b6f4da0/cache-22670505c562e0d4.arrow\n",
      "/opt/conda/lib/python3.8/site-packages/transformers/generation_utils.py:1359: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 448 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken: 59.84694576263428\n",
      "The WER of model: 38.76\n",
      "The CER of model: 22.21\n",
      "The model size is: 37.76M\n",
      "['parambharat', 'whisper-tiny-ml']\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "wer_list = []\n",
    "cer_list = []\n",
    "model_size_list = []\n",
    "time_list = []\n",
    "evaluate_whisper_model_common_voice(\"parambharat/whisper-tiny-ml\", wer_list, cer_list, model_size_list, time_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79adbf54-62c9-455a-824d-7243c1a5966d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[38.76]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "wer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696c44de-cdd0-44f7-a698-a5c59a001c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[22.21]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "cer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdf119e-6424-44c1-84af-94fc4dd52b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['37.76M']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "model_size_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0214fb-4b3d-4f47-9e3c-ab18d7f5ad11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[59.84694576263428]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "time_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cf6b8a-97ed-4dd1-ad26-97e17d6009ed",
   "metadata": {},
   "source": [
    "### Faster-Whisper models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c375a69-97f2-4bbe-8cf7-d218b0484f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WhisperModel(\"kurianbenoy/vegam-whisper-medium-ml-fp16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c910aceb-655d-4908-b04d-91b768242627",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_common_voice_malayalam_dataset()\n",
    "t = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17e82bf4-f109-4378-b573-79a7f9f6f456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'client_id': '82e6e487a5bf6fd5901946fc6e05ec523f0bc9fb574fbd7128b955f021a0831d629d8f6d61a7b107e8f1cbf9652d0cfb22c535bf999860db0ffdcd0f25f48261',\n",
       " 'path': '/home/.cache/huggingface/datasets/downloads/extracted/2351c96984ecb73430e25907bb4c930df191ec6cd4e5d087deafed9b0ba1e99a/ml_test_0/common_voice_ml_32261077.mp3',\n",
       " 'audio': {'path': '/home/.cache/huggingface/datasets/downloads/extracted/2351c96984ecb73430e25907bb4c930df191ec6cd4e5d087deafed9b0ba1e99a/ml_test_0/common_voice_ml_32261077.mp3',\n",
       "  'array': array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          9.95938535e-06, -7.94161679e-06,  4.42485316e-06]),\n",
       "  'sampling_rate': 16000},\n",
       " 'sentence': 'ഇന്ദിരാവധത്തിനെ തുടര്ന്നുണ്ടായ സിഖ് വിരുദ്ധ കലാപമാണ് വിഭജനത്തിനുശേഷം സ്വതന്ത്ര ഇന്ത്യ കണ്ടതില് വെച്ചു ഏറ്റവും രൂക്ഷമായ വംശീയകലാപം.',\n",
       " 'up_votes': 2,\n",
       " 'down_votes': 0,\n",
       " 'age': '',\n",
       " 'gender': '',\n",
       " 'accent': '',\n",
       " 'locale': 'ml',\n",
       " 'segment': '',\n",
       " 'norm_text': 'ഇന ദ ര വധത ത ന ത ടര ന ന ണ ട യ സ ഖ വ ര ദ ധ കല പമ ണ വ ഭജനത ത ന ശ ഷ സ വതന ത ര ഇന ത യ കണ ടത ല വ ച ച ഏറ റവ ര ക ഷമ യ വ ശ യകല പ '}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b126e02-8ba8-4a67-89b6-99ada54ab491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language 'ba' with probability 0.361816\n"
     ]
    }
   ],
   "source": [
    "segments, info = model.transcribe(t[\"audio\"][\"array\"], beam_size=5)\n",
    "print(\"Detected language '%s' with probability %f\" % (info.language, info.language_probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a18295a6-c3bc-49b3-b7b5-2a16ef8c3a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ഇന്ദിര വധത്തിനെ തുടർന്നുണ്ടായ സിഖുവിരുദ്ധ കലാപമാണ് വിഭജനത്തിനു ശേഷം സ്വതന്ത്ര്യ ഇന്ത്യ കണ്ടെത്തിൽ വെച്ച'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([segment.text for segment in segments])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0b3d4538-dddb-4396-a4e2-f370c3e6ef82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def evaluate_faster_whisper_model_common_voice(\n",
    "        model_name: str, # The model name\n",
    "        werlist: List[float], # WER List\n",
    "        cerlist: List[float],# CER list\n",
    "        modelsizelist: List[str], # model size list\n",
    "        timelist: List[float], # time(s) list\n",
    "        bs:int =16, # batch size. Default value is 16.\n",
    "        compute_type:str=\"float16\", # The compute type supported by faster-Whisper\n",
    "        beam_size=1, # beam size\n",
    ")->None:\n",
    "    \"\"\"A utility function for calculing WER in Common voice dataset provided a model name in huggingface.\n",
    "       You can store a WER, CER, ModelSize, TimeList to calculate results cumulatively over different epochs\n",
    "    \"\"\"\n",
    "    dataset = load_common_voice_malayalam_dataset()\n",
    "    model = WhisperModel(model_name, device=\"cuda\", compute_type=compute_type)\n",
    "     \n",
    "    \n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    start = time.time()\n",
    "    for x in tqdm(dataset):\n",
    "        segments, info = model.transcribe(x[\"audio\"][\"array\"], beam_size=beam_size)\n",
    "        predictions_raw.append(\" \".join([segment.text for segment in segments]))\n",
    "        references_raw.append(x[\"sentence\"])\n",
    "        predictions.append(normalizer(\" \".join([segment.text for segment in segments])))\n",
    "        references.append(normalizer(x[\"sentence\"]))\n",
    "              \n",
    "    end = time.time()\n",
    "    print(f\"Total time taken: {end - start}\")\n",
    "    timelist.append(end - start)\n",
    "    \n",
    "    df = pd.DataFrame({\"predictions\": predictions, \"ground_truth\": references})\n",
    "    df[\"model_name\"] = model_name\n",
    "    df[\"wer\"] = df.apply(lambda row: wer(normalizer(row[\"ground_truth\"]), normalizer(row[\"predictions\"])), axis=1)\n",
    "    df[\"cer\"] = df.apply(lambda row: cer(normalizer(row[\"ground_truth\"]), normalizer(row[\"predictions\"])), axis=1)\n",
    "    df[\"total_time\"] = end-start\n",
    "    \n",
    "    rwer = wer(references, predictions)\n",
    "    rwer = round(100 * rwer, 2)\n",
    "    werlist.append(rwer)\n",
    "    print(f\"The WER of model: {rwer}\")\n",
    "\n",
    "    rcer = cer(references, predictions)\n",
    "    rcer = round(100 * rcer, 2)\n",
    "    cerlist.append(rcer)\n",
    "    print(f\"The CER of model: {rcer}\")\n",
    "    \n",
    "    # print(f\"The model size is: {get_model_size(whisper_asr.model)}\")\n",
    "    # modelsizelist.append(get_model_size(whisper_asr.model))\n",
    "    # df[\"model_size\"] = get_model_size(whisper_asr.model)\n",
    "    \n",
    "    save_name = model_name.split(\"/\")\n",
    "    print(save_name)\n",
    "    df.to_parquet(f\"{save_name[0]}_{save_name[1]}_commonvoice.parquet\")\n",
    "    \n",
    "    clear_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fb54b3a1-3b1a-4452-8e93-a4e572fb98cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### evaluate_faster_whisper_model_common_voice\n",
       "\n",
       ">      evaluate_faster_whisper_model_common_voice (model_name:str,\n",
       ">                                                  werlist:List[float],\n",
       ">                                                  cerlist:List[float],\n",
       ">                                                  modelsizelist:List[str],\n",
       ">                                                  timelist:List[float],\n",
       ">                                                  bs:int=16,\n",
       ">                                                  compute_type:str='float16',\n",
       ">                                                  beam_size=1)\n",
       "\n",
       "A utility function for calculing WER in Common voice dataset provided a model name in huggingface.\n",
       "You can store a WER, CER, ModelSize, TimeList to calculate results cumulatively over different epochs\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| model_name | str |  | The model name |\n",
       "| werlist | List |  | WER List |\n",
       "| cerlist | List |  | CER list |\n",
       "| modelsizelist | List |  | model size list |\n",
       "| timelist | List |  | time(s) list |\n",
       "| bs | int | 16 | batch size. Default value is 16. |\n",
       "| compute_type | str | float16 | The compute type supported by faster-Whisper |\n",
       "| beam_size | int | 1 | beam size |\n",
       "| **Returns** | **None** |  |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### evaluate_faster_whisper_model_common_voice\n",
       "\n",
       ">      evaluate_faster_whisper_model_common_voice (model_name:str,\n",
       ">                                                  werlist:List[float],\n",
       ">                                                  cerlist:List[float],\n",
       ">                                                  modelsizelist:List[str],\n",
       ">                                                  timelist:List[float],\n",
       ">                                                  bs:int=16,\n",
       ">                                                  compute_type:str='float16',\n",
       ">                                                  beam_size=1)\n",
       "\n",
       "A utility function for calculing WER in Common voice dataset provided a model name in huggingface.\n",
       "You can store a WER, CER, ModelSize, TimeList to calculate results cumulatively over different epochs\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| model_name | str |  | The model name |\n",
       "| werlist | List |  | WER List |\n",
       "| cerlist | List |  | CER list |\n",
       "| modelsizelist | List |  | model size list |\n",
       "| timelist | List |  | time(s) list |\n",
       "| bs | int | 16 | batch size. Default value is 16. |\n",
       "| compute_type | str | float16 | The compute type supported by faster-Whisper |\n",
       "| beam_size | int | 1 | beam size |\n",
       "| **Returns** | **None** |  |  |"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(evaluate_faster_whisper_model_common_voice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "13198c8b-3af6-4e0d-914a-c1cabe280bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "600e88a427884070b3912fa4dc7f0bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken: 91.5117712020874\n",
      "The WER of model: 24.71\n",
      "The CER of model: 18.57\n",
      "['kurianbenoy', 'vegam-whisper-medium-ml-fp16']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([24.71], [18.57], [], [91.5117712020874])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "wer_list = []\n",
    "cer_list = []\n",
    "model_size_list = []\n",
    "time_list = []\n",
    "evaluate_faster_whisper_model_common_voice(\"kurianbenoy/vegam-whisper-medium-ml-fp16\", wer_list, cer_list, model_size_list, time_list)\n",
    "wer_list, cer_list, model_size_list, time_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "72fa3f31-9c06-4455-b1f2-2f794eb46769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce8d415684d940aba3e666e9bb4a6028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken: 132.16357469558716\n",
      "The WER of model: 20.5\n",
      "The CER of model: 13.95\n",
      "['kurianbenoy', 'vegam-whisper-medium-ml-fp16']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([20.5], [13.95], [], [132.16357469558716])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "wer_list = []\n",
    "cer_list = []\n",
    "model_size_list = []\n",
    "time_list = []\n",
    "evaluate_faster_whisper_model_common_voice(\"kurianbenoy/vegam-whisper-medium-ml-fp16\", wer_list, cer_list, model_size_list, time_list, beam_size=5)\n",
    "wer_list, cer_list, model_size_list, time_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3dab6e-9f54-4e4c-bac0-83d3dfd20c36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
