{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d381ea18-77f9-4749-8411-426aeacec856",
   "metadata": {},
   "source": [
    "## Common Voice benchmarking tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7f4a0c-5038-4be1-b569-94a8c5b51827",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp commonvoice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4ce661-cbba-48f1-86a2-e6f68ff800fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nbdev'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#| hide\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnbdev\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mshowdoc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nbdev'"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f6bcbd-7707-442b-81d0-1bc7f0d058d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, Audio\n",
    "from jiwer import wer, cer\n",
    "from transformers import pipeline\n",
    "\n",
    "from malayalam_asr_benchmarking.utils import whisper_norm, is_target_text_in_range, get_text, normalise, data, get_model_size, clear_gpu_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798e1946",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_common_voice_malayalam_dataset():\n",
    "    dataset = load_dataset(\n",
    "            \"mozilla-foundation/common_voice_11_0\",\n",
    "            \"ml\",\n",
    "            split=\"test\"\n",
    "    )\n",
    "    dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "    dataset = dataset.map(normalise)\n",
    "    dataset = dataset.filter(is_target_text_in_range, input_columns=[\"norm_text\"])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c48f20f-b900-438d-ae89-3067d9166167",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def evaluate_whisper_model_common_voice(model_name: \"str\")->None:\n",
    "    whisper_asr = pipeline(\n",
    "            \"automatic-speech-recognition\", model=model_name, device=0\n",
    "        )\n",
    "    dataset = load_common_voice_malayalam_dataset()\n",
    "    \n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    start = time.time()\n",
    "    for out in whisper_asr(data(dataset), batch_size=16):\n",
    "        predictions.append(whisper_norm(out[\"text\"]))\n",
    "        references.append(out[\"reference\"][0])\n",
    "        \n",
    "        \n",
    "    end = time.time()\n",
    "    print(f\"Total time taken: {end - start}\")\n",
    "    \n",
    "    df = pd.DataFrame({\"predictions\": predictions, \"ground_truth\": references})\n",
    "    df[\"model_name\"] = model_name\n",
    "    df[\"wer\"] = df.apply(lambda row: wer(row[\"ground_truth\"], row[\"predictions\"]), axis=1)\n",
    "    df[\"cer\"] = df.apply(lambda row: cer(row[\"ground_truth\"], row[\"predictions\"]), axis=1)\n",
    "    df[\"total_time\"] = end-start\n",
    "    \n",
    "    rwer = wer(references, predictions)\n",
    "    rwer = round(100 * rwer, 2)\n",
    "    print(f\"The WER of model: {rwer}\")\n",
    "\n",
    "    rcer = cer(references, predictions)\n",
    "    rcer = round(100 * rcer, 2)\n",
    "    print(f\"The CER of model: {rcer}\")\n",
    "    \n",
    "    print(f\"The model size is: {get_model_size(whisper_asr.model)}\")\n",
    "    df[\"model_size\"] = get_model_size(whisper_asr.model)\n",
    "    df.to_parquet(f\"test_file.parquet\")\n",
    "    \n",
    "    clear_gpu_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecebe2cc-e590-4b39-aa30-a2d317db72d8",
   "metadata": {},
   "source": [
    "## Testing with a sample model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c2f808-0803-4c54-9bd7-f4df36ab7228",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset common_voice_11_0 (/home/.cache/huggingface/datasets/mozilla-foundation___common_voice_11_0/ml/11.0.0/2c65b95d99ca879b1b1074ea197b65e0497848fd697fdb0582e0f6b75b6f4da0)\n",
      "Loading cached processed dataset at /home/.cache/huggingface/datasets/mozilla-foundation___common_voice_11_0/ml/11.0.0/2c65b95d99ca879b1b1074ea197b65e0497848fd697fdb0582e0f6b75b6f4da0/cache-374585c2877047e3.arrow\n",
      "Loading cached processed dataset at /home/.cache/huggingface/datasets/mozilla-foundation___common_voice_11_0/ml/11.0.0/2c65b95d99ca879b1b1074ea197b65e0497848fd697fdb0582e0f6b75b6f4da0/cache-22670505c562e0d4.arrow\n",
      "/opt/conda/lib/python3.8/site-packages/transformers/generation_utils.py:1359: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 448 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken: 65.49683594703674\n",
      "The WER of model: 38.31\n",
      "The CER of model: 21.93\n",
      "The model size is: 37.76M\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "evaluate_whisper_model_common_voice(\"parambharat/whisper-tiny-ml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79adbf54-62c9-455a-824d-7243c1a5966d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
