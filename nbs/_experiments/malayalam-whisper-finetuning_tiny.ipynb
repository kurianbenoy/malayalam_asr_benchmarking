{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74018de8",
   "metadata": {
    "id": "75b58048-7d14-4fc6-8085-1fc08c81b4a6",
    "papermill": {
     "duration": 0.011673,
     "end_time": "2023-03-19T19:20:27.333868",
     "exception": false,
     "start_time": "2023-03-19T19:20:27.322195",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Fine-Tune Whisper With 🤗 Transformers and Streaming Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46e2d0d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T19:20:27.356409Z",
     "iopub.status.busy": "2023-03-19T19:20:27.355651Z",
     "iopub.status.idle": "2023-03-19T19:21:00.650296Z",
     "shell.execute_reply": "2023-03-19T19:21:00.649041Z"
    },
    "id": "nc_zDlLqESDL",
    "outputId": "c27bf11e-e317-49fd-ce61-d930cf74f59f",
    "papermill": {
     "duration": 33.309045,
     "end_time": "2023-03-19T19:21:00.653201",
     "exception": false,
     "start_time": "2023-03-19T19:20:27.344156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tfx-bsl 1.12.0 requires google-api-python-client<2,>=1.7.11, but you have google-api-python-client 2.79.0 which is incompatible.\r\n",
      "tfx-bsl 1.12.0 requires pyarrow<7,>=6, but you have pyarrow 11.0.0 which is incompatible.\r\n",
      "tensorflow-transform 1.12.0 requires pyarrow<7,>=6, but you have pyarrow 11.0.0 which is incompatible.\r\n",
      "apache-beam 2.44.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.6 which is incompatible.\r\n",
      "apache-beam 2.44.0 requires pyarrow<10.0.0,>=0.15.1, but you have pyarrow 11.0.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install -Uqq datasets transformers evaluate jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cc87a3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T19:21:00.675565Z",
     "iopub.status.busy": "2023-03-19T19:21:00.675217Z",
     "iopub.status.idle": "2023-03-19T19:21:04.411718Z",
     "shell.execute_reply": "2023-03-19T19:21:04.410389Z"
    },
    "papermill": {
     "duration": 3.750378,
     "end_time": "2023-03-19T19:21:04.414092",
     "exception": false,
     "start_time": "2023-03-19T19:21:00.663714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-19 19:21:01--  https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip\r\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\r\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 42989872 (41M) [application/x-httpd-php]\r\n",
      "Saving to: ‘drugsCom_raw.zip’\r\n",
      "\r\n",
      "drugsCom_raw.zip    100%[===================>]  41.00M  70.8MB/s    in 0.6s    \r\n",
      "\r\n",
      "2023-03-19 19:21:02 (70.8 MB/s) - ‘drugsCom_raw.zip’ saved [42989872/42989872]\r\n",
      "\r\n",
      "Archive:  drugsCom_raw.zip\r\n",
      "  inflating: drugsComTest_raw.tsv    \r\n",
      "  inflating: drugsComTrain_raw.tsv   \r\n"
     ]
    }
   ],
   "source": [
    "!wget \"https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip\"\n",
    "!unzip drugsCom_raw.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d6466ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T19:21:04.438766Z",
     "iopub.status.busy": "2023-03-19T19:21:04.438444Z",
     "iopub.status.idle": "2023-03-19T19:21:04.446065Z",
     "shell.execute_reply": "2023-03-19T19:21:04.445069Z"
    },
    "papermill": {
     "duration": 0.021819,
     "end_time": "2023-03-19T19:21:04.448202",
     "exception": false,
     "start_time": "2023-03-19T19:21:04.426383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5.0.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyarrow\n",
    "pyarrow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b255af5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T19:21:04.471125Z",
     "iopub.status.busy": "2023-03-19T19:21:04.470785Z",
     "iopub.status.idle": "2023-03-19T19:21:28.122399Z",
     "shell.execute_reply": "2023-03-19T19:21:28.121167Z"
    },
    "papermill": {
     "duration": 23.666189,
     "end_time": "2023-03-19T19:21:28.125185",
     "exception": false,
     "start_time": "2023-03-19T19:21:04.458996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.7/site-packages (22.3.1)\r\n",
      "Collecting pip\r\n",
      "  Downloading pip-23.0.1-py3-none-any.whl (2.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: pip\r\n",
      "  Attempting uninstall: pip\r\n",
      "    Found existing installation: pip 22.3.1\r\n",
      "    Uninstalling pip-22.3.1:\r\n",
      "      Successfully uninstalled pip-22.3.1\r\n",
      "Successfully installed pip-23.0.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mRequirement already satisfied: pyarrow in /opt/conda/lib/python3.7/site-packages (11.0.0)\r\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.7/site-packages (from pyarrow) (1.21.6)\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python -m pip install --upgrade pip\n",
    "!pip install --user --upgrade pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c6e0174",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T19:21:28.150779Z",
     "iopub.status.busy": "2023-03-19T19:21:28.149776Z",
     "iopub.status.idle": "2023-03-19T19:21:28.216507Z",
     "shell.execute_reply": "2023-03-19T19:21:28.214914Z"
    },
    "papermill": {
     "duration": 0.081599,
     "end_time": "2023-03-19T19:21:28.218685",
     "exception": true,
     "start_time": "2023-03-19T19:21:28.137086",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportWarning",
     "evalue": "To use `datasets`, the module `pyarrow>=6.0.0` is required, and the current version of `pyarrow` doesn't match this condition.\nIf you are running this in a Google Colab, you should probably just restart the runtime to use the right version of `pyarrow`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportWarning\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23/1888155392.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"drugsComTrain_raw.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"drugsComTest_raw.tsv\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# \\t is the tab character in Python\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdrug_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyarrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajor\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     raise ImportWarning(\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;34m\"To use `datasets`, the module `pyarrow>=6.0.0` is required, and the current version of `pyarrow` doesn't match this condition.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;34m\"If you are running this in a Google Colab, you should probably just restart the runtime to use the right version of `pyarrow`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     )\n",
      "\u001b[0;31mImportWarning\u001b[0m: To use `datasets`, the module `pyarrow>=6.0.0` is required, and the current version of `pyarrow` doesn't match this condition.\nIf you are running this in a Google Colab, you should probably just restart the runtime to use the right version of `pyarrow`."
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data_files = {\"train\": \"drugsComTrain_raw.tsv\", \"test\": \"drugsComTest_raw.tsv\"}\n",
    "# \\t is the tab character in Python\n",
    "drug_dataset = load_dataset(\"csv\", data_files=data_files, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4ea61d",
   "metadata": {
    "id": "W6laeKZ5F4MG",
    "outputId": "aa2cd044-945d-4430-85e7-2b041a313b95",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from huggingface_hub import notebook_login\n",
    "\n",
    "# notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9ea3c5",
   "metadata": {
    "id": "afe0d503-ae4e-4aa7-9af4-dbcba52db41e",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb480726",
   "metadata": {
    "id": "b219c9dd-39b6-4a95-b2a1-3f547a1e7bc0",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Load Dataset with Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0445a8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T19:00:59.026805Z",
     "iopub.status.busy": "2023-03-19T19:00:59.025820Z",
     "iopub.status.idle": "2023-03-19T19:00:59.034451Z",
     "shell.execute_reply": "2023-03-19T19:00:59.033262Z",
     "shell.execute_reply.started": "2023-03-19T19:00:59.026734Z"
    },
    "id": "065a8cf7-e54f-4ac3-900e-609c80714fca",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import interleave_datasets, load_dataset\n",
    "\n",
    "def load_streaming_dataset(dataset_name, dataset_config_name, split, **kwargs):\n",
    "    if \"+\" in split:\n",
    "        # load multiple splits separated by the `+` symbol *with* streaming mode\n",
    "        dataset_splits = [load_dataset(dataset_name, dataset_config_name, split=split_name, streaming=True, **kwargs) for split_name in split.split(\"+\")]\n",
    "        # interleave multiple splits to form one dataset\n",
    "        interleaved_dataset = interleave_datasets(dataset_splits)\n",
    "        return interleaved_dataset\n",
    "    else:\n",
    "        # load a single split *with* streaming mode\n",
    "        dataset = load_dataset(dataset_name, dataset_config_name, split=split, streaming=True, **kwargs)\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bd1528",
   "metadata": {
    "id": "a2787582-554f-44ce-9f38-4180a5ed6b44",
    "outputId": "48e08dfd-1a9d-4b7e-fbaf-c75760964cac",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import IterableDatasetDict\n",
    "\n",
    "raw_datasets = IterableDatasetDict()\n",
    "\n",
    "raw_datasets[\"train\"] = load_streaming_dataset(\"thennal/IMaSC\", None, \"train\")  # set split=\"train+validation\" for low-resource\n",
    "raw_datasets[\"test\"] = load_streaming_dataset(\"thennal/msc\", None, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675ddbd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T19:17:12.629211Z",
     "iopub.status.busy": "2023-03-19T19:17:12.628142Z",
     "iopub.status.idle": "2023-03-19T19:17:34.573638Z",
     "shell.execute_reply": "2023-03-19T19:17:34.572699Z",
     "shell.execute_reply.started": "2023-03-19T19:17:12.629164Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import IterableDatasetDict\n",
    "\n",
    "raw_datasets = IterableDatasetDict()\n",
    "raw_datasets[\"train\"] = load_dataset(\"thennal/IMaSC\", split=\"train\").select(range(10_000))\n",
    "raw_datasets[\"test\"] = load_dataset(\"thennal/msc\", split=\"train\").select(range(1_000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccfa286",
   "metadata": {
    "id": "2d63b2d2-f68a-4d74-b7f1-5127f6d16605",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Prepare Processor and Pre-Process Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6820d3c4",
   "metadata": {
    "id": "601c3099-1026-439e-93e2-5635b3ba5a73",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "The ASR pipeline can be de-composed into three stages: \n",
    "1) A feature extractor which pre-processes the raw audio-inputs\n",
    "2) The model which performs the sequence-to-sequence mapping \n",
    "3) A tokenizer which post-processes the model outputs to text format\n",
    "\n",
    "In 🤗 Transformers, the Whisper model has an associated feature extractor and tokenizer, \n",
    "called [WhisperFeatureExtractor](https://huggingface.co/docs/transformers/main/model_doc/whisper#transformers.WhisperFeatureExtractor)\n",
    "and [WhisperTokenizer](https://huggingface.co/docs/transformers/main/model_doc/whisper#transformers.WhisperTokenizer) \n",
    "respectively. To make our lives simple, these two objects are wrapped under a single class, called the [WhisperProcessor](https://huggingface.co/docs/transformers/model_doc/whisper#transformers.WhisperProcessor). We can call the WhisperProcessor to perform \n",
    "both the audio pre-processing and the text token post-processing. In doing so, we only need to keep track of two objects during training: \n",
    "the `processor` and the `model`.\n",
    "\n",
    "If using a multilingual checkpoint, you should set the `\"language\"` to your target text language. You should also set the task to `\"transcribe\"` for speech recogntition and `\"translate\"` for speech translation. These arguments modify the behaviour of the tokenizer - they should be set correctly to ensure the target labels are encoded properly. These arguments should be omitted for English-only fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37568e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T19:17:34.576355Z",
     "iopub.status.busy": "2023-03-19T19:17:34.575774Z",
     "iopub.status.idle": "2023-03-19T19:17:43.968865Z",
     "shell.execute_reply": "2023-03-19T19:17:43.967760Z",
     "shell.execute_reply.started": "2023-03-19T19:17:34.576313Z"
    },
    "id": "77d9f0c5-8607-4642-a8ac-c3ab2e223ea6",
    "outputId": "52f70546-3bed-48ae-caca-093a49597eb1",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import WhisperProcessor\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny\", language=\"Malayalam\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e3993b",
   "metadata": {
    "id": "381acd09-0b0f-4d04-9eb3-f028ac0e5f2c",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Pre-Process Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98745f72",
   "metadata": {
    "id": "bf10cd3e-924e-44fc-8790-46e413de7b3d",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Let's have a look at the dataset features. Pay particular attention to the `\"audio\"` column - this details the sampling rate of our audio inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fc0eff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T19:17:43.971602Z",
     "iopub.status.busy": "2023-03-19T19:17:43.970271Z",
     "iopub.status.idle": "2023-03-19T19:17:43.981942Z",
     "shell.execute_reply": "2023-03-19T19:17:43.980698Z",
     "shell.execute_reply.started": "2023-03-19T19:17:43.971559Z"
    },
    "id": "ab5a13b4-9bd4-4aa0-aef2-b3de9b762988",
    "outputId": "6ee8550c-7a80-43dd-d035-d44fc95bb12a",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_datasets[\"train\"].features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4f2a11",
   "metadata": {
    "id": "5a679f05-063d-41b3-9b58-4fc9c6ccf4fd",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Since our input audio is sampled at 48kHz, we need to _downsample_ it to\n",
    "16kHz prior to passing it to the Whisper feature extractor, 16kHz being the sampling rate expected by the Whisper model. \n",
    "\n",
    "We'll set the audio inputs to the correct sampling rate using dataset's \n",
    "[`cast_column`](https://huggingface.co/docs/datasets/package_reference/main_classes.html?highlight=cast_column#datasets.DatasetDict.cast_column)\n",
    "method. This operation does not change the audio in-place, \n",
    "but rather signals to `datasets` to resample audio samples _on the fly_ the \n",
    "first time that they are loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7e44e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T19:17:43.985847Z",
     "iopub.status.busy": "2023-03-19T19:17:43.985110Z",
     "iopub.status.idle": "2023-03-19T19:17:45.877139Z",
     "shell.execute_reply": "2023-03-19T19:17:45.876004Z",
     "shell.execute_reply.started": "2023-03-19T19:17:43.985777Z"
    },
    "id": "3ab6a724-3d1e-478b-a9e9-d2f85feb6c39",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import Audio\n",
    "\n",
    "raw_datasets = raw_datasets.cast_column(\"audio\", Audio(sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ea21e8",
   "metadata": {
    "id": "161322c2-94f3-4d26-9e1d-d9d5202ca3cf",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "We'll define our pre-processing strategy. We advise that you **do not** lower-case the transcriptions or remove punctuation unless mixing different datasets. This will enable you to fine-tune Whisper models that can predict punctuation and casing. Later, you will see how we can evaluate the predictions without punctuation or casing, so that the models benefit from the WER improvement obtained by normalising the transcriptions while still predicting fully formatted transcriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128c4033",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T19:17:45.879376Z",
     "iopub.status.busy": "2023-03-19T19:17:45.878979Z",
     "iopub.status.idle": "2023-03-19T19:17:45.886563Z",
     "shell.execute_reply": "2023-03-19T19:17:45.885396Z",
     "shell.execute_reply.started": "2023-03-19T19:17:45.879339Z"
    },
    "id": "d041650e-1c48-4439-87b3-5b6f4a514107",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers.models.whisper.english_normalizer import BasicTextNormalizer\n",
    "\n",
    "do_lower_case = False\n",
    "do_remove_punctuation = False\n",
    "\n",
    "normalizer = BasicTextNormalizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e208e8",
   "metadata": {
    "id": "bfaa935b-a11d-497c-88c1-0c4d1bb3247b",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Now we can write a function to prepare our data ready for the model:\n",
    "1. We load and resample the audio data by calling `batch[\"audio\"]`. As explained above, 🤗 Datasets performs any necessary resampling operations on the fly.\n",
    "2. We use the feature extractor to compute the log-Mel spectrogram input features from our 1-dimensional audio array.\n",
    "3. We perform any optional pre-processing (lower-case or remove punctuation).\n",
    "4. We encode the transcriptions to label ids through the use of the tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f324e689",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T19:17:45.888862Z",
     "iopub.status.busy": "2023-03-19T19:17:45.888283Z",
     "iopub.status.idle": "2023-03-19T19:17:45.896835Z",
     "shell.execute_reply": "2023-03-19T19:17:45.895584Z",
     "shell.execute_reply.started": "2023-03-19T19:17:45.888824Z"
    },
    "id": "c085911c-a10a-41ef-8874-306e0503e9bb",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    # load and (possibly) resample audio data to 16kHz\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    # compute log-Mel input features from input audio array \n",
    "    batch[\"input_features\"] = processor.feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "    # compute input length of audio sample in seconds\n",
    "    batch[\"input_length\"] = len(audio[\"array\"]) / audio[\"sampling_rate\"]\n",
    "    \n",
    "    # optional pre-processing steps\n",
    "    transcription = batch[\"text\"]\n",
    "    if do_lower_case:\n",
    "        transcription = transcription.lower()\n",
    "    if do_remove_punctuation:\n",
    "        transcription = normalizer(transcription).strip()\n",
    "    \n",
    "    # encode target text to label ids\n",
    "    batch[\"labels\"] = processor.tokenizer(transcription).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824be619",
   "metadata": {
    "id": "70b319fb-2439-4ef6-a70d-a47bf41c4a13",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "We can apply the data preparation function to all of our training examples using 🤗 Datasets' `.map` method. We'll remove all of the columns from the raw training data, leaving just the `input_features` and `labels` defined in the `prepare_dataset` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc813e92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T19:18:23.618027Z",
     "iopub.status.busy": "2023-03-19T19:18:23.616930Z"
    },
    "id": "a37a7cdb-9013-427f-8de9-6a8d0e9dc684",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectorized_datasets = raw_datasets.map(prepare_dataset, remove_columns=list(next(iter(raw_datasets.values())).features)).with_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59716e5",
   "metadata": {
    "id": "3d59b37e-4950-47ec-9e3e-2cf2ec7fc750",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "We can now define how we shuffle the data in the train split. The size of the subset we load is set by the variable `buffer_size`. You can increase or decrease this depending on your memory constraints. In this example, the `buffer_size` is set to 500, meaning 500 samples are loaded before shuffling across the subset. The larger we set this value, the closer to True offline shuffling. The `seed` is set for reproducibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b33489",
   "metadata": {
    "id": "1b145699-acfc-4b1d-93a2-a2ad3d62674c",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectorized_datasets[\"train\"] = vectorized_datasets[\"train\"].shuffle(\n",
    "    buffer_size=500,\n",
    "    seed=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb753fff",
   "metadata": {
    "id": "666b9ef0-7909-4e1e-a419-87604d233e29",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Finally, we filter any training data with audio samples longer than 30s. These samples would otherwise be truncated by the Whisper feature-extractor which could affect the stability of training. We define a function that returns `True` for samples that are less than 30s, and `False` for those that are longer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa98318",
   "metadata": {
    "id": "01cb25ef-4bb0-4325-9461-f59198acadf6",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_input_length = 30.0\n",
    "\n",
    "def is_audio_in_length_range(length):\n",
    "    return length < max_input_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb42cd7",
   "metadata": {
    "id": "28e37ac3-b1c5-465b-8586-7cfd8d76b0f1",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "We apply our filter function to all samples of our training dataset through 🤗 Datasets' `.filter` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acfc1ad",
   "metadata": {
    "id": "333f7f6e-6053-4d3b-8924-c733c79b82ac",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectorized_datasets[\"train\"] = vectorized_datasets[\"train\"].filter(\n",
    "    is_audio_in_length_range,\n",
    "    input_columns=[\"input_length\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f02ce0",
   "metadata": {
    "id": "263a5a58-0239-4a25-b0df-c625fc9c5810",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70368f8e",
   "metadata": {
    "id": "a693e768-c5a6-453f-89a1-b601dcf7daf7",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Now that we've prepared our data, we're ready to dive into the training pipeline. \n",
    "The [🤗 Trainer](https://huggingface.co/transformers/master/main_classes/trainer.html?highlight=trainer)\n",
    "will do much of the heavy lifting for us. All we have to do is:\n",
    "\n",
    "- Define a data collator: the data collator takes our pre-processed data and prepares PyTorch tensors ready for the model.\n",
    "\n",
    "- Evaluation metrics: during evaluation, we want to evaluate the model using the [word error rate (WER)](https://huggingface.co/metrics/wer) metric. We need to define a `compute_metrics` function that handles this computation.\n",
    "\n",
    "- Load a pre-trained checkpoint: we need to load a pre-trained checkpoint and configure it correctly for training.\n",
    "\n",
    "- Define the training configuration: this will be used by the 🤗 Trainer to define the training schedule."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00540e2",
   "metadata": {
    "id": "8d230e6d-624c-400a-bbf5-fa660881df25",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Define a Data Collator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ab0534",
   "metadata": {
    "id": "04def221-0637-4a69-b242-d3f0c1d0ee78",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "The data collator for a sequence-to-sequence speech model is unique in the sense that it \n",
    "treats the `input_features` and `labels` independently: the  `input_features` must be \n",
    "handled by the feature extractor and the `labels` by the tokenizer.\n",
    "\n",
    "The `input_features` are already padded to 30s and converted to a log-Mel spectrogram \n",
    "of fixed dimension by action of the feature extractor, so all we have to do is convert the `input_features`\n",
    "to batched PyTorch tensors. We do this using the feature extractor's `.pad` method with `return_tensors=pt`.\n",
    "\n",
    "The `labels` on the other hand are un-padded. We first pad the sequences\n",
    "to the maximum length in the batch using the tokenizer's `.pad` method. The padding tokens \n",
    "are then replaced by `-100` so that these tokens are **not** taken into account when \n",
    "computing the loss. We then cut the BOS token from the start of the label sequence as we \n",
    "append it later during training.\n",
    "\n",
    "We can leverage the `WhisperProcessor` we defined earlier to perform both the \n",
    "feature extractor and the tokenizer operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46beb83d",
   "metadata": {
    "id": "8326221e-ec13-4731-bb4e-51e5fc1486c5",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543ccb3c",
   "metadata": {
    "id": "3cae7dbf-8a50-456e-a3a8-7fd005390f86",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Let's initialise the data collator we've just defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fdf88d",
   "metadata": {
    "id": "fc834702-c0d3-4a96-b101-7b87be32bf42",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3409ff3a",
   "metadata": {
    "id": "d62bb2ab-750a-45e7-82e9-61d6f4805698",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cadac52",
   "metadata": {
    "id": "66fee1a7-a44c-461e-b047-c3917221572e",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "We'll use the word error rate (WER) metric, the 'de-facto' metric for assessing \n",
    "ASR systems. For more information, refer to the WER [docs](https://huggingface.co/metrics/wer). We'll load the WER metric from 🤗 Evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15fda49",
   "metadata": {
    "id": "b22b4011-f31f-4b57-b684-c52332f92890",
    "outputId": "a4a0dc25-3828-4c30-adae-1ca49201e0d7",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"wer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4495dc00",
   "metadata": {
    "id": "509f96d7-3f11-4f37-add9-f74a0c44f3fc",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "We then simply have to define a function that takes our model \n",
    "predictions and returns the WER metric. This function, called\n",
    "`compute_metrics`, first replaces `-100` with the `pad_token_id`\n",
    "in the `label_ids` (undoing the step we applied in the \n",
    "data collator to ignore padded tokens correctly in the loss).\n",
    "It then decodes the predicted and label ids to strings. Finally,\n",
    "it computes the WER between the predictions and reference labels. \n",
    "Here, we have the option of evaluating with the 'normalised' transcriptions \n",
    "and predictions. We recommend you set this to `True` to benefit from the WER \n",
    "improvement obtained by normalising the transcriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7629de4f",
   "metadata": {
    "id": "a11d1bfc-9e28-460f-a287-72d8f7bc1acb",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# evaluate with the 'normalised' WER\n",
    "do_normalize_eval = True\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # replace -100 with the pad_token_id\n",
    "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    if do_normalize_eval:\n",
    "        pred_str = [normalizer(pred) for pred in pred_str]\n",
    "        label_str = [normalizer(label) for label in label_str]\n",
    "        # filtering step to only evaluate the samples that correspond to non-zero references:\n",
    "        pred_str = [pred_str[i] for i in range(len(pred_str)) if len(label_str[i]) > 0]\n",
    "        label_str = [label_str[i] for i in range(len(label_str)) if len(label_str[i]) > 0]\n",
    "\n",
    "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a57722",
   "metadata": {
    "id": "daf2a825-6d9f-4a23-b145-c37c0039075b",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Load a Pre-Trained Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b56727",
   "metadata": {
    "id": "437a97fa-4864-476b-8abc-f28b8166cfa5",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Now let's load the pre-trained Whisper `small` checkpoint. Again, this \n",
    "is trivial through use of 🤗 Transformers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730c71fa",
   "metadata": {
    "id": "5a10cc4b-07ec-4ebd-ac1d-7c601023594f",
    "outputId": "83e9f3e7-5f8c-4ac3-cd68-29ec0af9c1b8",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2c13d1",
   "metadata": {
    "id": "a15ead5f-2277-4a39-937b-585c2497b2df",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Override generation arguments - no tokens are forced as decoder outputs (see [`forced_decoder_ids`](https://huggingface.co/docs/transformers/main_classes/text_generation#transformers.generation_utils.GenerationMixin.generate.forced_decoder_ids)), no tokens are suppressed during generation (see [`suppress_tokens`](https://huggingface.co/docs/transformers/main_classes/text_generation#transformers.generation_utils.GenerationMixin.generate.suppress_tokens)). Set `use_cache` to False since we're using gradient checkpointing, and the two are incompatible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb6e471",
   "metadata": {
    "id": "62038ba3-88ed-4fce-84db-338f50dcd04f",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.config.forced_decoder_ids = None\n",
    "model.config.suppress_tokens = []\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf0d160",
   "metadata": {
    "id": "2178dea4-80ca-47b6-b6ea-ba1915c90c06",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Define the Training Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25579e0",
   "metadata": {
    "id": "c21af1e9-0188-4134-ac82-defc7bdcc436",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "In the final step, we define all the parameters related to training. Here, you can set the `max_steps` to train for longer. For more detail on the training arguments, refer to the Seq2SeqTrainingArguments [docs](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.Seq2SeqTrainingArguments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0252b220",
   "metadata": {
    "id": "0ae3e9af-97b7-4aa0-ae85-20b23b5bcb3a",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./\",\n",
    "    per_device_train_batch_size=32,\n",
    "    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=500,\n",
    "    max_steps=5000,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=8,\n",
    "    predict_with_generate=False,\n",
    "    generation_max_length=225,\n",
    "    save_steps=1000,\n",
    "    eval_steps=1000,\n",
    "    logging_steps=25,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19a5e7d",
   "metadata": {
    "id": "b3a944d8-3112-4552-82a0-be25988b3857",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**Note**: if one does not want to upload the model checkpoints to the Hub, \n",
    "set `push_to_hub=False`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b130da88",
   "metadata": {
    "id": "393c883e-3e50-492c-bd58-f51dbf15ee56",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "We then define a custom [Callback](https://huggingface.co/docs/transformers/main_classes/callback) that is called by the 🤗 Trainer on the end of each epoch. The Callback reinitialises and reshuffles the streaming dataset at the beginning of each new epoch - this gives different shuffling across our subsets for every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea825af",
   "metadata": {
    "id": "3ac16b62-b3c0-4c68-8f3d-9ecf471534b2",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "from transformers.trainer_pt_utils import IterableDatasetShard\n",
    "from torch.utils.data import IterableDataset\n",
    "\n",
    "# trainer callback to reinitialise and reshuffle the streamable datasets at the beginning of each epoch\n",
    "class ShuffleCallback(TrainerCallback):\n",
    "    def on_epoch_begin(self, args, state, control, train_dataloader, **kwargs):\n",
    "        if isinstance(train_dataloader.dataset, IterableDatasetShard):\n",
    "            pass  # set_epoch() is handled by the Trainer\n",
    "        elif isinstance(train_dataloader.dataset, IterableDataset):\n",
    "            train_dataloader.dataset.set_epoch(train_dataloader.dataset._epoch + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a52758",
   "metadata": {
    "id": "bac29114-d226-4f54-97cf-8718c9f94e1e",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "We can forward the training arguments to the 🤗 Trainer along with our model,\n",
    "dataset, data collator, `compute_metrics` function and custom callback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4006542b",
   "metadata": {
    "id": "d546d7fe-0543-479a-b708-2ebabec19493",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=vectorized_datasets[\"train\"],\n",
    "    eval_dataset=vectorized_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor,\n",
    "    callbacks=[ShuffleCallback()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4d313b",
   "metadata": {
    "id": "67ab88c3-7091-4e51-8ad5-f5cacbe18449",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "We'll save the model and processor to the output directory before training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6326568b",
   "metadata": {
    "id": "a1ccb9ed-cbc8-4419-91c0-651e9424b672",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(training_args.output_dir)\n",
    "processor.save_pretrained(training_args.output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d095fd40",
   "metadata": {
    "id": "7f404cf9-4345-468c-8196-4bd101d9bd51",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ef68b9",
   "metadata": {
    "id": "5e8b8d56-5a70-4f68-bd2e-f0752d0bd112",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Training will take approximately 5-10 hours depending on your GPU. The peak GPU memory for the given training configuration is approximately 36GB. \n",
    "Depending on your GPU, it is possible that you will encounter a CUDA `\"out-of-memory\"` error when you launch training. \n",
    "In this case, you can reduce the `per_device_train_batch_size` incrementally by factors of 2 \n",
    "and employ [`gradient_accumulation_steps`](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.Seq2SeqTrainingArguments.gradient_accumulation_steps)\n",
    "to compensate.\n",
    "\n",
    "To launch training, simply execute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3f664c",
   "metadata": {
    "id": "ee8b7b8e-1c9a-4d77-9137-1778a629e6de",
    "outputId": "0f945d41-baa9-4b86-f1ad-d76fc7a7122a",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ee5857",
   "metadata": {
    "id": "747c6a6e",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "(note that training may take some time to commence as we load the first training data samples with streaming mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e6d38f",
   "metadata": {
    "id": "810ced54-7187-4a06-b2fe-ba6dcca94dc3",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "We can label our checkpoint with the `whisper-event` tag on push by setting the appropriate key-word arguments (kwargs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2fd56c",
   "metadata": {
    "id": "6dd0e310-9b07-4133-ac14-2ed2d7524e22",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# kwargs = {\n",
    "#     \"dataset_tags\": \"mozilla-foundation/common_voice_11_0\",\n",
    "#     \"dataset\": \"Common Voice 11.0\",  # a 'pretty' name for the training dataset\n",
    "#     \"language\": \"es\",\n",
    "#     \"model_name\": \"Whisper Small Es - Sanchit Gandhi\",  # a 'pretty' name for your model\n",
    "#     \"finetuned_from\": \"openai/whisper-small\",\n",
    "#     \"tasks\": \"automatic-speech-recognition\",\n",
    "#     \"tags\": \"whisper-event\",\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db97c9d",
   "metadata": {
    "id": "090d676a-f944-4297-a938-a40eda0b2b68",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "The training results can now be uploaded to the Hub. To do so, execute the `push_to_hub` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0ec21e",
   "metadata": {
    "id": "95737cda-c5dd-4887-a4d0-dfcb0d61d977",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trainer.push_to_hub(**kwargs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 71.110131,
   "end_time": "2023-03-19T19:21:28.750263",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-19T19:20:17.640132",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
