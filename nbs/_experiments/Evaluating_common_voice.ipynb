{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a352890-30dd-4584-977b-728862c853c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers.models.whisper.english_normalizer import BasicTextNormalizer\n",
    "from datasets import load_dataset, Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4375fab-0b2f-49ae-b2e8-4d166862f4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_target_text_in_range(ref):\n",
    "    if ref.strip() == \"ignore time segment in scoring\":\n",
    "        return False\n",
    "    else:\n",
    "        return ref.strip() != \"\"\n",
    "\n",
    "\n",
    "def get_text(sample):\n",
    "    if \"text\" in sample:\n",
    "        return sample[\"text\"]\n",
    "    elif \"sentence\" in sample:\n",
    "        return sample[\"sentence\"]\n",
    "    elif \"normalized_text\" in sample:\n",
    "        return sample[\"normalized_text\"]\n",
    "    elif \"transcript\" in sample:\n",
    "        return sample[\"transcript\"]\n",
    "    elif \"transcription\" in sample:\n",
    "        return sample[\"transcription\"]\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Expected transcript column of either 'text', 'sentence', 'normalized_text' or 'transcript'. Got sample of \"\n",
    "            \".join{sample.keys()}. Ensure a text column name is present in the dataset.\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d02f2113-af2d-4671-960f-517d7fe9c65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_norm = BasicTextNormalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d70ca751-8a30-4fe4-a8ef-9d32ae7cb72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(batch):\n",
    "    batch[\"norm_text\"] = whisper_norm(get_text(batch))\n",
    "    return batch\n",
    "\n",
    "\n",
    "def data(dataset):\n",
    "    for i, item in enumerate(dataset):\n",
    "        yield {**item[\"audio\"], \"reference\": item[\"norm_text\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1caa1fa-b5f3-42b1-9f27-3fcad9d76454",
   "metadata": {},
   "source": [
    "## Evaluate Param Bharats Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a37e0d4-6c9d-48f2-90c3-5fd01bc9734f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar  4 14:32:52 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro RTX 5000     Off  | 00000000:1E:00.0 Off |                  Off |\n",
      "| 34%   33C    P8    13W / 230W |      0MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb2737af-c956-42f4-8124-0338ebb469a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"parambharat/whisper-small-ml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8fe9946-47ca-4908-ba24-f62d13b1a025",
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_asr = pipeline(\n",
    "        \"automatic-speech-recognition\", model=model_id, device=0\n",
    "    )\n",
    "\n",
    "dataset = load_dataset(\n",
    "        \"mozilla-foundation/common_voice_11_0\",\n",
    "        \"ml\",\n",
    "        split=\"test\"\n",
    ")\n",
    "\n",
    "# Only uncomment for debugging\n",
    "#dataset = dataset.take(args.max_eval_samples)\n",
    "\n",
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "dataset = dataset.map(normalise)\n",
    "dataset = dataset.filter(is_target_text_in_range, input_columns=[\"norm_text\"])\n",
    "\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d37bc4c9-c841-435f-bbd1-1b3e75dd8491",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/generation/utils.py:1273: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 448 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 33s, sys: 53 s, total: 7min 26s\n",
      "Wall time: 4min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "# run streamed inference\n",
    "for out in whisper_asr(data(dataset), batch_size=16):\n",
    "    predictions.append(whisper_norm(out[\"text\"]))\n",
    "    references.append(out[\"reference\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ab467e6-6485-4cdf-b562-2058592e13a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jiwer import wer, cer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fdfedd08-986b-49dd-a982-c4a1d2d95b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The WER of model: 21.65\n"
     ]
    }
   ],
   "source": [
    "rwer = wer(references, predictions)\n",
    "rwer = round(100 * rwer, 2)\n",
    "print(f\"The WER of model: {rwer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de25e297-6cb1-426c-bc8a-64f3460fde8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jiwer import cer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8856632d-d598-4d70-bb62-25943fcea9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CER of model: 11.78\n"
     ]
    }
   ],
   "source": [
    "rcer = cer(references, predictions)\n",
    "rcer = round(100 * rcer, 2)\n",
    "print(f\"The CER of model: {rcer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927c7b8a-aa98-4b0b-84c1-ed850e6291ac",
   "metadata": {},
   "source": [
    "## Common function to evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25afef0a-de0a-4218-8b0e-b34b047fdab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "from jiwer import wer, cer\n",
    "from transformers import pipeline\n",
    "from transformers.models.whisper.english_normalizer import BasicTextNormalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb113bc6-5285-4595-af1a-6a850466c349",
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_norm = BasicTextNormalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68fa35eb-706f-48dd-bf44-404016cea964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_target_text_in_range(ref):\n",
    "    if ref.strip() == \"ignore time segment in scoring\":\n",
    "        return False\n",
    "    else:\n",
    "        return ref.strip() != \"\"\n",
    "\n",
    "\n",
    "def get_text(sample):\n",
    "    if \"text\" in sample:\n",
    "        return sample[\"text\"]\n",
    "    elif \"sentence\" in sample:\n",
    "        return sample[\"sentence\"]\n",
    "    elif \"normalized_text\" in sample:\n",
    "        return sample[\"normalized_text\"]\n",
    "    elif \"transcript\" in sample:\n",
    "        return sample[\"transcript\"]\n",
    "    elif \"transcription\" in sample:\n",
    "        return sample[\"transcription\"]\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Expected transcript column of either 'text', 'sentence', 'normalized_text' or 'transcript'. Got sample of \"\n",
    "            \".join{sample.keys()}. Ensure a text column name is present in the dataset.\"\n",
    "        )\n",
    "\n",
    "def normalise(batch):\n",
    "    batch[\"norm_text\"] = whisper_norm(get_text(batch))\n",
    "    return batch\n",
    "\n",
    "def data(dataset):\n",
    "    for i, item in enumerate(dataset):\n",
    "        yield {**item[\"audio\"], \"reference\": item[\"norm_text\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae6cf9d8-70b3-4e87-9644-2d2b3f5d5c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_whisper_model_common_voice(model_name: \"str\")->None:\n",
    "    whisper_asr = pipeline(\n",
    "            \"automatic-speech-recognition\", model=model_name, device=0\n",
    "        )\n",
    "\n",
    "    dataset = load_dataset(\n",
    "            \"mozilla-foundation/common_voice_11_0\",\n",
    "            \"ml\",\n",
    "            split=\"test\"\n",
    "    )\n",
    "    dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "    dataset = dataset.map(normalise)\n",
    "    dataset = dataset.filter(is_target_text_in_range, input_columns=[\"norm_text\"])\n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    for out in whisper_asr(data(dataset), batch_size=32):\n",
    "        predictions.append(whisper_norm(out[\"text\"]))\n",
    "        references.append(out[\"reference\"][0])\n",
    "        \n",
    "    rwer = wer(references, predictions)\n",
    "    rwer = round(100 * rwer, 2)\n",
    "    print(f\"The WER of model: {rwer}\")\n",
    "\n",
    "    rcer = cer(references, predictions)\n",
    "    rcer = round(100 * rcer, 2)\n",
    "    print(f\"The CER of model: {rcer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5168cac4-6fbd-4b3f-b565-e40033eb99a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset common_voice_11_0 (/home/.cache/huggingface/datasets/mozilla-foundation___common_voice_11_0/ml/11.0.0/2c65b95d99ca879b1b1074ea197b65e0497848fd697fdb0582e0f6b75b6f4da0)\n",
      "Loading cached processed dataset at /home/.cache/huggingface/datasets/mozilla-foundation___common_voice_11_0/ml/11.0.0/2c65b95d99ca879b1b1074ea197b65e0497848fd697fdb0582e0f6b75b6f4da0/cache-b5fde927f6328b58.arrow\n",
      "Loading cached processed dataset at /home/.cache/huggingface/datasets/mozilla-foundation___common_voice_11_0/ml/11.0.0/2c65b95d99ca879b1b1074ea197b65e0497848fd697fdb0582e0f6b75b6f4da0/cache-34d1ec8a736a6ac3.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The WER of model: 21.65\n",
      "The CER of model: 11.78\n"
     ]
    }
   ],
   "source": [
    "evaluate_whisper_model_common_voice(\"parambharat/whisper-small-ml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b881f223-554c-450a-b19a-91da209787ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
