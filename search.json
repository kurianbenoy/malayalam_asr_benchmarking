[
  {
    "objectID": "utils.html",
    "href": "utils.html",
    "title": "Common Utilities",
    "section": "",
    "text": "source\n\ndata\n\n data (dataset)\n\n\nsource\n\n\nget_text\n\n get_text (sample)\n\n\nsource\n\n\nget_model_size\n\n get_model_size (model)\n\n\nsource\n\n\nclear_gpu_memory\n\n clear_gpu_memory ()\n\n\nsource\n\n\nstore_results_as_dataset\n\n store_results_as_dataset (predictions, predictions_raw, references,\n                           references_raw, model_name, time, model_size,\n                           twer, tcer, saving_name)\n\n\n\n\n\nMade by Kurian Benoy. See the code.",
    "crumbs": [
      "Common Utilities"
    ]
  },
  {
    "objectID": "msc.html",
    "href": "msc.html",
    "title": "Evaluation Malayalam Speech Corpus(MSC) dataset",
    "section": "",
    "text": "Loading dataset and evaluating model\n\nsource\n\n\nload_malayalam_speech_corpus_dataset\n\n load_malayalam_speech_corpus_dataset ()\n\n\n\nEvaluating Whisper based model\n\nsource\n\n\nevaluate_whisper_model_msc\n\n evaluate_whisper_model_msc (model_name:str, werlist:List[float],\n                             cerlist:List[float], modelsizelist:List[str],\n                             timelist:List[float], bs:int=16)\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nmodel_name\nstr\n\nThe model name\n\n\nwerlist\ntyping.List[float]\n\nWER List\n\n\ncerlist\ntyping.List[float]\n\nCER list\n\n\nmodelsizelist\ntyping.List[str]\n\nmodel size list\n\n\ntimelist\ntyping.List[float]\n\ntime(s) list\n\n\nbs\nint\n16\nbatch size\n\n\nReturns\nNone\n\n\n\n\n\n\n\nTesting with a sample model\n\nwer_list = []\ncer_list = []\nmodel_size_list = []\ntime_list = []\n\n\nevaluate_whisper_model_msc(\"openai/whisper-tiny\", wer_list, cer_list, model_size_list, time_list)\n\n\n\n\n\n\n\nKeyboardInterrupt: \n\n\n\nevaluate_whisper_model_msc(\"anuragshas/whisper-large-v2-ml\", wer_list, cer_list, model_size_list, time_list, bs=4)\n\n\n\nEvaluating Faster-whisper based models\n\nsource\n\n\nevaluate_faster_whisper_model_msc\n\n evaluate_faster_whisper_model_msc (model_name:str, werlist:List[float],\n                                    cerlist:List[float],\n                                    modelsizelist:List[str],\n                                    timelist:List[float], bs:int=16,\n                                    compute_type:str='float16',\n                                    beam_size=1)\n\nA utility function for calculing WER in Common voice dataset provided a model name in huggingface. You can store a WER, CER, ModelSize, TimeList to calculate results cumulatively over different epochs\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nmodel_name\nstr\n\nThe model name\n\n\nwerlist\ntyping.List[float]\n\nWER List\n\n\ncerlist\ntyping.List[float]\n\nCER list\n\n\nmodelsizelist\ntyping.List[str]\n\nmodel size list\n\n\ntimelist\ntyping.List[float]\n\ntime(s) list\n\n\nbs\nint\n16\nbatch size. Default value is 16.\n\n\ncompute_type\nstr\nfloat16\nThe compute type supported by faster-Whisper\n\n\nbeam_size\nint\n1\nbeam size\n\n\nReturns\nNone\n\n\n\n\n\n\n\nEvaluating faster-Whisper based model\n\nwer_list = []\ncer_list = []\nmodel_size_list = []\ntime_list = []\nevaluate_faster_whisper_model_msc(\"kurianbenoy/vegam-whisper-medium-ml-fp16\", wer_list, cer_list, model_size_list, time_list)\nwer_list, cer_list, model_size_list, time_list\n\n\n\n\n\nMade by Kurian Benoy. See the code.",
    "crumbs": [
      "Evaluation Malayalam Speech Corpus(MSC) dataset"
    ]
  },
  {
    "objectID": "commonvoice.html",
    "href": "commonvoice.html",
    "title": "Evaluation Common Voice - malayalam subset dataset",
    "section": "",
    "text": "source\nMade by Kurian Benoy. See the code.",
    "crumbs": [
      "Evaluation Common Voice - malayalam subset dataset"
    ]
  },
  {
    "objectID": "commonvoice.html#testing-with-a-sample-model",
    "href": "commonvoice.html#testing-with-a-sample-model",
    "title": "Evaluation Common Voice - malayalam subset dataset",
    "section": "Testing with a sample model",
    "text": "Testing with a sample model\n\nwer_list = []\ncer_list = []\nmodel_size_list = []\ntime_list = []\nevaluate_whisper_model_common_voice(\"parambharat/whisper-tiny-ml\", wer_list, cer_list, model_size_list, time_list)\n\nFound cached dataset common_voice_11_0 (/home/.cache/huggingface/datasets/mozilla-foundation___common_voice_11_0/ml/11.0.0/2c65b95d99ca879b1b1074ea197b65e0497848fd697fdb0582e0f6b75b6f4da0)\nLoading cached processed dataset at /home/.cache/huggingface/datasets/mozilla-foundation___common_voice_11_0/ml/11.0.0/2c65b95d99ca879b1b1074ea197b65e0497848fd697fdb0582e0f6b75b6f4da0/cache-374585c2877047e3.arrow\nLoading cached processed dataset at /home/.cache/huggingface/datasets/mozilla-foundation___common_voice_11_0/ml/11.0.0/2c65b95d99ca879b1b1074ea197b65e0497848fd697fdb0582e0f6b75b6f4da0/cache-22670505c562e0d4.arrow\n/opt/conda/lib/python3.8/site-packages/transformers/generation_utils.py:1359: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 448 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n\n\nTotal time taken: 59.84694576263428\nThe WER of model: 38.76\nThe CER of model: 22.21\nThe model size is: 37.76M\n['parambharat', 'whisper-tiny-ml']\n\n\n\nwer_list\n\n[38.76]\n\n\n\ncer_list\n\n[22.21]\n\n\n\nmodel_size_list\n\n['37.76M']\n\n\n\ntime_list\n\n[59.84694576263428]\n\n\n\nFaster-Whisper models\n\nmodel = WhisperModel(\"kurianbenoy/vegam-whisper-medium-ml-fp16\")\n\ndataset = load_common_voice_malayalam_dataset()\nt = dataset[0]\n\nsegments, info = model.transcribe(t[\"audio\"][\"array\"], beam_size=5)\nprint(\"Detected language '%s' with probability %f\" % (info.language, info.language_probability))\n\n\n\" \".join([segment.text for segment in segments])\n\n'ഇന്ദിര വധത്തിനെ തുടർന്നുണ്ടായ സിഖുവിരുദ്ധ കലാപമാണ് വിഭജനത്തിനു ശേഷം സ്വതന്ത്ര്യ ഇന്ത്യ കണ്ടെത്തിൽ വെച്ച'\n\n\n\nsource\n\n\nevaluate_faster_whisper_model_common_voice\n\n evaluate_faster_whisper_model_common_voice (model_name:str,\n                                             werlist:List[float],\n                                             cerlist:List[float],\n                                             modelsizelist:List[str],\n                                             timelist:List[float],\n                                             bs:int=16,\n                                             compute_type:str='float16',\n                                             beam_size=1)\n\nA utility function for calculing WER in Common voice dataset provided a model name in huggingface. You can store a WER, CER, ModelSize, TimeList to calculate results cumulatively over different epochs\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nmodel_name\nstr\n\nThe model name\n\n\nwerlist\ntyping.List[float]\n\nWER List\n\n\ncerlist\ntyping.List[float]\n\nCER list\n\n\nmodelsizelist\ntyping.List[str]\n\nmodel size list\n\n\ntimelist\ntyping.List[float]\n\ntime(s) list\n\n\nbs\nint\n16\nbatch size. Default value is 16.\n\n\ncompute_type\nstr\nfloat16\nThe compute type supported by faster-Whisper\n\n\nbeam_size\nint\n1\nbeam size\n\n\nReturns\nNone\n\n\n\n\n\n\n\nEvaluating faster-Whisper based model\n\nwer_list = []\ncer_list = []\nmodel_size_list = []\ntime_list = []\nevaluate_faster_whisper_model_common_voice(\"kurianbenoy/vegam-whisper-medium-ml-fp16\", wer_list, cer_list, model_size_list, time_list)\nwer_list, cer_list, model_size_list, time_list\n\n\n\n\nTotal time taken: 91.5117712020874\nThe WER of model: 24.71\nThe CER of model: 18.57\n['kurianbenoy', 'vegam-whisper-medium-ml-fp16']\n\n\n([24.71], [18.57], [], [91.5117712020874])",
    "crumbs": [
      "Evaluation Common Voice - malayalam subset dataset"
    ]
  },
  {
    "objectID": "whisper_event.html",
    "href": "whisper_event.html",
    "title": "Benchmarking Results in Malayalam datasets",
    "section": "",
    "text": "HuggingFace Team conducted a whisper event on fine tuning Whisper model to achieve the State of the art results performance for various languages.\nDuring this competitions lot of models where evaluated on dataset like Common Voice.\nFor the language Malayalam, the results are as follows in Common Voice dataset subsection of Malayalam:\n\n\n\nResults in common voice\n\n\nThere was an evaluation in Google Fluers Malaylam subsection as well:\n\n\n\nResults in Fluers\n\n\nDetails are from Huggingface whisper-event leaderboard\nMade by Kurian Benoy. See the code.",
    "crumbs": [
      "Benchmarking Results in Malayalam datasets"
    ]
  },
  {
    "objectID": "whisper_event.html#whisper-event-leaderboard",
    "href": "whisper_event.html#whisper-event-leaderboard",
    "title": "Benchmarking Results in Malayalam datasets",
    "section": "",
    "text": "HuggingFace Team conducted a whisper event on fine tuning Whisper model to achieve the State of the art results performance for various languages.\nDuring this competitions lot of models where evaluated on dataset like Common Voice.\nFor the language Malayalam, the results are as follows in Common Voice dataset subsection of Malayalam:\n\n\n\nResults in common voice\n\n\nThere was an evaluation in Google Fluers Malaylam subsection as well:\n\n\n\nResults in Fluers\n\n\nDetails are from Huggingface whisper-event leaderboard",
    "crumbs": [
      "Benchmarking Results in Malayalam datasets"
    ]
  },
  {
    "objectID": "whisper_event.html#benchmarking-in-common-voice-dataset",
    "href": "whisper_event.html#benchmarking-in-common-voice-dataset",
    "title": "Benchmarking Results in Malayalam datasets",
    "section": "Benchmarking in Common Voice Dataset",
    "text": "Benchmarking in Common Voice Dataset\n\nimport pandas as pd\nfrom tqdm import tqdm\n\nfrom malayalam_asr_benchmarking.commonvoice import evaluate_whisper_model_common_voice\n\n\nASR models to benchmark\n\nasr_models = [\"thennal/whisper-medium-ml\",\n              \"anuragshas/whisper-large-v2-ml\",\n              \"DrishtiSharma/whisper-large-v2-malayalam\",\n              \"parambharat/whisper-small-ml\",\n              \"parambharat/whisper-base-ml\",\n              \"parambharat/whisper-tiny-ml\"\n             ]\n\n\nopenai_models = [\n    \"openai/whisper-tiny\",\n    \"openai/whisper-base\",\n    \"openai/whisper-small\",\n    \"openai/whisper-medium\",\n    \"openai/whisper-large\",\n    \"openai/whisper-large-v2\",\n]\n\n\n\nRunning across all asr models\n\nwer_list = []\ncer_list = []\nmodel_size_list = []\ntime_list = []\n\n\nfor asr in tqdm(asr_models):\n    evaluate_whisper_model_common_voice(asr, wer_list, cer_list, model_size_list, time_list)\n\n  0%|          | 0/7 [00:00&lt;?, ?it/s]Found cached dataset common_voice_11_0 (/home/.cache/huggingface/datasets/mozilla-foundation___common_voice_11_0/ml/11.0.0/2c65b95d99ca879b1b1074ea197b65e0497848fd697fdb0582e0f6b75b6f4da0)\nLoading cached processed dataset at /home/.cache/huggingface/datasets/mozilla-foundation___common_voice_11_0/ml/11.0.0/2c65b95d99ca879b1b1074ea197b65e0497848fd697fdb0582e0f6b75b6f4da0/cache-374585c2877047e3.arrow\nLoading cached processed dataset at /home/.cache/huggingface/datasets/mozilla-foundation___common_voice_11_0/ml/11.0.0/2c65b95d99ca879b1b1074ea197b65e0497848fd697fdb0582e0f6b75b6f4da0/cache-22670505c562e0d4.arrow\n/opt/conda/lib/python3.8/site-packages/transformers/generation_utils.py:1359: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 448 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n\n\n\nwer_list\n\n[11.56, 24.46, 21.65, 26.25, 30.33, 300.7, 38.31]\n\n\n\n\nStore results in pandas\n\ndf = pd.DataFrame({\"models\": asr_models, \"wer\": wer_list, \"cer\": cer_list, \"model size\": model_size_list,\"time(s)\": time_list,})\n\n\ndf.head(7)\n\n\n\n\n\n\n\n\n\nmodels\nwer\ncer\nmodel size\ntime(s)\n\n\n\n\n0\nthennal/whisper-medium-ml\n11.56\n5.41\n763.86M\n924.979711\n\n\n1\nanuragshas/whisper-large-v2-ml\n24.46\n11.64\n1.54B\n1779.561592\n\n\n2\nparambharat/whisper-small-ml\n21.65\n11.78\n241.73M\n273.555688\n\n\n3\nDrishtiSharma/whisper-large-v2-malayalam\n26.25\n13.17\n1.54B\n1773.661774\n\n\n4\nparambharat/whisper-base-ml\n30.33\n16.16\n72.59M\n96.419609\n\n\n5\nkurianbenoy/whisper_malayalam_largev2\n300.70\n292.82\n1.54B\n5034.771624\n\n\n6\nparambharat/whisper-tiny-ml\n38.31\n21.93\n37.76M\n59.535259\n\n\n\n\n\n\n\n\n\ndf.to_parquet(\"/home/commonvoice_benchmarking_results.parquet\")\n\n\nevaluate_whisper_model_common_voice(\"kurianbenoy/whisper-small-ml-gmasc\", [], [], [], [])\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n\n\n\n\n\nTotal time taken: 56.87792730331421\nThe WER of model: 41.12\nThe CER of model: 21.24\nThe model size is: 241.73M\n['kurianbenoy', 'whisper-small-ml-gmasc']\n\n\n\n\nRunning OpenAI ASR models\n\nwer_list = []\ncer_list = []\nmodel_size_list = []\ntime_list = []\n\n\nfor asr in tqdm(openai_models):\n    evaluate_whisper_model_common_voice(asr, wer_list, cer_list, model_size_list, time_list)\n\n  0%|          | 0/6 [00:02&lt;?, ?it/s]\n\nKeyboardInterrupt\n\n\n\n\n\n\n\nwer_list = [154.21, 118.39, 100.06, 127.97, 125.73, 100.26]\n\ncer_list = [180.45, 131.08, 95.04, 136.43, 139.62, 93.6]\n\nmodel_size_list = ['37.76M', '72.59M', '241.73M', '763.86M', '1.54B', '1.54B']\n\ntime_list = [22.277158498764038, 22.35258674621582, 25.442846059799194, 53.88049054145813, 82.74607968330383, 71.14292621612549]\n\n\nevaluate_whisper_model_common_voice(\"openai/whisper-large-v2\", wer_list, cer_list, model_size_list, time_list, bs=4)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFound cached dataset common_voice_11_0 (/home/.cache/huggingface/datasets/mozilla-foundation___common_voice_11_0/ml/11.0.0/2c65b95d99ca879b1b1074ea197b65e0497848fd697fdb0582e0f6b75b6f4da0)\nLoading cached processed dataset at /home/.cache/huggingface/datasets/mozilla-foundation___common_voice_11_0/ml/11.0.0/2c65b95d99ca879b1b1074ea197b65e0497848fd697fdb0582e0f6b75b6f4da0/cache-374585c2877047e3.arrow\nLoading cached processed dataset at /home/.cache/huggingface/datasets/mozilla-foundation___common_voice_11_0/ml/11.0.0/2c65b95d99ca879b1b1074ea197b65e0497848fd697fdb0582e0f6b75b6f4da0/cache-22670505c562e0d4.arrow\n/opt/conda/lib/python3.8/site-packages/transformers/generation_utils.py:1359: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 448 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n\n\nTotal time taken: 71.14292621612549\nThe WER of model: 100.26\nThe CER of model: 93.6\nThe model size is: 1.54B\n['openai', 'whisper-large-v2']\n\n\n\nopenai_models\n\n['openai/whisper-tiny',\n 'openai/whisper-base',\n 'openai/whisper-small',\n 'openai/whisper-medium',\n 'openai/whisper-large',\n 'openai/whisper-large-v2']\n\n\n\ndf = pd.DataFrame({\"models\": openai_models,\n                   \"wer\": wer_list,\n                   \"cer\": cer_list,\n                   \"model size\": model_size_list,\n                   \"time(s)\": time_list\n                  })\n\n\ndf.head()\n\n\n\n\n\n\n\n\n\nmodels\nwer\ncer\nmodel size\ntime(s)\n\n\n\n\n0\nopenai/whisper-tiny\n154.21\n180.45\n37.76M\n22.277158\n\n\n1\nopenai/whisper-base\n118.39\n131.08\n72.59M\n22.352587\n\n\n2\nopenai/whisper-small\n100.06\n95.04\n241.73M\n25.442846\n\n\n3\nopenai/whisper-medium\n127.97\n136.43\n763.86M\n53.880491\n\n\n4\nopenai/whisper-large\n125.73\n139.62\n1.54B\n82.746080\n\n\n\n\n\n\n\n\n\ndf.to_parquet(\"/home/commonvoice_benchmarking_openai_results.parquet\")",
    "crumbs": [
      "Benchmarking Results in Malayalam datasets"
    ]
  },
  {
    "objectID": "whisper_event.html#benchmarking-in-msc-dataset",
    "href": "whisper_event.html#benchmarking-in-msc-dataset",
    "title": "Benchmarking Results in Malayalam datasets",
    "section": "Benchmarking in MSC dataset",
    "text": "Benchmarking in MSC dataset\n\nfrom malayalam_asr_benchmarking.msc import evaluate_whisper_model_msc\n\n\nevaluate_whisper_model_msc(\"openai/whisper-medium\",\n                           wer_list,\n                           cer_list,\n                           model_size_list,\n                           time_list,\n                           bs=8\n                          )\n\nFound cached dataset parquet (/home/.cache/huggingface/datasets/thennal___parquet/thennal--msc-cc9d10989b2ac4bd/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\nLoading cached processed dataset at /home/.cache/huggingface/datasets/thennal___parquet/thennal--msc-cc9d10989b2ac4bd/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-30f1618974cdefce.arrow\nLoading cached processed dataset at /home/.cache/huggingface/datasets/thennal___parquet/thennal--msc-cc9d10989b2ac4bd/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-e4f860ca9b159c26.arrow\n/opt/conda/lib/python3.8/site-packages/transformers/generation_utils.py:1359: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 448 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n\n\nprocess of calculating predictions\ncompleted getting predictions\nTotal time taken: 673.2912940979004\nThe WER of model: 101.45\nThe CER of model: 104.23\nThe model size is: 763.86M\n['openai', 'whisper-medium']\n\n\n\n\n\n\nevaluate_whisper_model_msc(\"openai/whisper-large-v2\",\n                           wer_list,\n                           cer_list,\n                           model_size_list,\n                           time_list,\n                           bs=4\n                          )\n\nFound cached dataset parquet (/home/.cache/huggingface/datasets/thennal___parquet/thennal--msc-cc9d10989b2ac4bd/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\nLoading cached processed dataset at /home/.cache/huggingface/datasets/thennal___parquet/thennal--msc-cc9d10989b2ac4bd/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-30f1618974cdefce.arrow\nLoading cached processed dataset at /home/.cache/huggingface/datasets/thennal___parquet/thennal--msc-cc9d10989b2ac4bd/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-e4f860ca9b159c26.arrow\n/opt/conda/lib/python3.8/site-packages/transformers/generation_utils.py:1359: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 448 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n\n\nprocess of calculating predictions\ncompleted getting predictions\nTotal time taken: 1040.2502796649933\nThe WER of model: 100.27\nThe CER of model: 102.4\nThe model size is: 1.54B\n['openai', 'whisper-large-v2']\n\n\n\n\n\n\nevaluate_whisper_model_msc(\"openai/whisper-large\",\n                           wer_list,\n                           cer_list,\n                           model_size_list,\n                           time_list,\n                           bs=4\n                          )\n\nFound cached dataset parquet (/home/.cache/huggingface/datasets/thennal___parquet/thennal--msc-cc9d10989b2ac4bd/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\nLoading cached processed dataset at /home/.cache/huggingface/datasets/thennal___parquet/thennal--msc-cc9d10989b2ac4bd/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-30f1618974cdefce.arrow\nLoading cached processed dataset at /home/.cache/huggingface/datasets/thennal___parquet/thennal--msc-cc9d10989b2ac4bd/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-e4f860ca9b159c26.arrow\n/opt/conda/lib/python3.8/site-packages/transformers/generation_utils.py:1359: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 448 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n\n\nprocess of calculating predictions\ncompleted getting predictions\nTotal time taken: 1067.5574433803558\nThe WER of model: 107.01\nThe CER of model: 113.62\nThe model size is: 1.54B\n['openai', 'whisper-large']\n\n\n\n\n\n\nevaluate_whisper_model_msc(\"kurianbenoy/whisper-small-ml-gmasc\", [], [], [], [])\n\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n\n\nprocess of calculating predictions\ncompleted getting predictions\nTotal time taken: 498.59665060043335\nThe WER of model: 32.07\nThe CER of model: 16.89\nThe model size is: 241.73M\n['kurianbenoy', 'whisper-small-ml-gmasc']",
    "crumbs": [
      "Benchmarking Results in Malayalam datasets"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "malayalam_asr_benchmarking",
    "section": "",
    "text": "Note\n\n\n\nA study to benchmark ASRs in Malayalam. Till now the project has benchmark based on Malayalam ASR models based in Whisper ASR and faster-whisper ASR.\nMade by Kurian Benoy. See the code.",
    "crumbs": [
      "malayalam_asr_benchmarking"
    ]
  },
  {
    "objectID": "index.html#objective-of-the-project",
    "href": "index.html#objective-of-the-project",
    "title": "malayalam_asr_benchmarking",
    "section": "",
    "text": "Note\n\n\n\nA study to benchmark ASRs in Malayalam. Till now the project has benchmark based on Malayalam ASR models based in Whisper ASR and faster-whisper ASR.",
    "crumbs": [
      "malayalam_asr_benchmarking"
    ]
  },
  {
    "objectID": "index.html#benchmarked-datasets",
    "href": "index.html#benchmarked-datasets",
    "title": "malayalam_asr_benchmarking",
    "section": "Benchmarked Datasets",
    "text": "Benchmarked Datasets\nTill now we have mainly benchmarked on two datasets:\n\nCommon Voice 11 Dataset\n\nI have now done benchmarking on Mozilla’s Common Voice 11 Malayalam subset. The benchmarking results can be found in the below dataset.\n\nMalayalam Speech Corpus\n\nI have now benchmarked on SMC’s Malayalam Speech corpus dataset. The benchmarking results can be found in the below dataset.",
    "crumbs": [
      "malayalam_asr_benchmarking"
    ]
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "malayalam_asr_benchmarking",
    "section": "Install",
    "text": "Install\npip install malayalam_asr_benchmarking\nor from github repository\n# Ensure git is installed, else install it. Eg: In ubuntu via apt install git\npip install git+https://github.com/kurianbenoy/malayalam_asr_benchmarking.git\nOr locally\n# Ensure git is installed, else install it. Eg: In ubuntu via apt install git\ngit clone https://github.com/kurianbenoy/malayalam_asr_benchmarking.git\ncd malayalam_asr_benchmarking\npip install -e .",
    "crumbs": [
      "malayalam_asr_benchmarking"
    ]
  },
  {
    "objectID": "index.html#setting-up-your-development-environment",
    "href": "index.html#setting-up-your-development-environment",
    "title": "malayalam_asr_benchmarking",
    "section": "Setting up your development environment",
    "text": "Setting up your development environment\nI am developing this project with nbdev. Please take some time reading up on nbdev … how it works, directives, etc… by checking out the walk-thrus and tutorials on the nbdev website\n\nStep 1: Install Quarto:\nnbdev_install_quarto\nOther options are mentioned in getting started to quarto",
    "crumbs": [
      "malayalam_asr_benchmarking"
    ]
  },
  {
    "objectID": "index.html#step-2-install-hooks",
    "href": "index.html#step-2-install-hooks",
    "title": "malayalam_asr_benchmarking",
    "section": "Step 2: Install hooks",
    "text": "Step 2: Install hooks\nnbdev_install_hooks",
    "crumbs": [
      "malayalam_asr_benchmarking"
    ]
  },
  {
    "objectID": "index.html#step-3-install-our-library",
    "href": "index.html#step-3-install-our-library",
    "title": "malayalam_asr_benchmarking",
    "section": "Step 3: Install our library",
    "text": "Step 3: Install our library\npip install -e '.[dev]'",
    "crumbs": [
      "malayalam_asr_benchmarking"
    ]
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "malayalam_asr_benchmarking",
    "section": "How to use",
    "text": "How to use\n\nEvaluate Whisper-based Malayalam ASR models\n\nfrom malayalam_asr_benchmarking.commonvoice import evaluate_whisper_model_common_voice\n\nwerlist = []\ncerlist = []\nmodelsizelist = []\ntimelist = []\n\nevaluate_whisper_model_common_voice(\"parambharat/whisper-tiny-ml\", werlist, cerlist, modelsizelist, timelist)\n\n\nfrom malayalam_asr_benchmarking.msc import evaluate_whisper_model_msc\n\nwerlist = []\ncerlist = []\nmodelsizelist = []\ntimelist = []\n\nevaluate_whisper_model_msc(\"parambharat/whisper-tiny-ml\", werlist, cerlist, modelsizelist, timelist)\n\n\n\nEvaluate faster-whisper based models\n\nfrom malayalam_asr_benchmarking.commonvoice import evaluate_faster_whisper_model_common_voice\n\nwerlist = []\ncerlist = []\nmodelsizelist = []\ntimelist = []\n\nevaluate_faster_whisper_model_common_voice(\"kurianbenoy/vegam-whisper-medium-ml\", werlist, cerlist, modelsizelist, timelist)\n\n\nfrom malayalam_asr_benchmarking.msc import evaluate_faster_whisper_model_msc\n\nwerlist = []\ncerlist = []\nmodelsizelist = []\ntimelist = []\n\nevaluate_faster_whisper_model_msc(\"kurianbenoy/vegam-whisper-medium-ml\", werlist, cerlist, modelsizelist, timelist)",
    "crumbs": [
      "malayalam_asr_benchmarking"
    ]
  }
]