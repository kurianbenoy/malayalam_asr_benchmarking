# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/02_msc.ipynb.

# %% auto 0
__all__ = ['normalizer', 'load_malayalam_speech_corpus_dataset', 'evaluate_whisper_model_msc',
           'evaluate_faster_whisper_model_msc']

# %% ../nbs/02_msc.ipynb 3
import time
from typing import List

import pandas as pd
from datasets import load_dataset, Audio
from faster_whisper import WhisperModel
from jiwer import wer, cer
from transformers import pipeline
from tqdm.notebook import tqdm
from whisper_normalizer.indic_normalizer import MalayalamNormalizer

from malayalam_asr_benchmarking.utils import (
    is_target_text_in_range,
    get_text,
    data,
    get_model_size,
    clear_gpu_memory,
    store_results_as_dataset,
)

# %% ../nbs/02_msc.ipynb 5
def load_malayalam_speech_corpus_dataset():
    dataset = load_dataset("thennal/msc", split="train")
    dataset = dataset.cast_column("audio", Audio(sampling_rate=16000))
    dataset = dataset.filter(is_target_text_in_range, input_columns=["text"])
    return dataset

# %% ../nbs/02_msc.ipynb 6
normalizer = MalayalamNormalizer()

# %% ../nbs/02_msc.ipynb 7
def evaluate_whisper_model_msc(
    model_name: str,  # The model name
    werlist: List[float],  # WER List
    cerlist: List[float],  # CER list
    modelsizelist: List[str],  # model size list
    timelist: List[float],  # time(s) list
    bs: int = 16,  # batch size
) -> None:
    whisper_asr = pipeline("automatic-speech-recognition", model=model_name, device=0)
    dataset = load_malayalam_speech_corpus_dataset()

    predictions = []
    references = []
    predictions_raw = []
    references_raw = []

    start = time.time()
    print("process of calculating predictions")
    for out in tqdm(whisper_asr(data(dataset), batch_size=bs)):
        predictions_raw.append(out["text"])
        references_raw.append(out["reference"][0])
        predictions.append(normalizer(out["text"]))
        references.append(normalizer(out["reference"][0]))

    print("completed getting predictions")
    end = time.time()
    print(f"Total time taken: {end - start}")
    timelist.append(end - start)

    rwer = wer(references, predictions)
    rwer = round(100 * rwer, 2)
    # df["total_wer"] = rwer
    werlist.append(rwer)
    print(f"The WER of model: {rwer}")

    rcer = cer(references, predictions)
    rcer = round(100 * rcer, 2)
    # df["total_cer"] = rcer
    cerlist.append(rcer)
    print(f"The CER of model: {rcer}")

    print(f"The model size is: {get_model_size(whisper_asr.model)}")
    modelsizelist.append(get_model_size(whisper_asr.model))
    # df["model_size"] = get_model_size(whisper_asr.model)

    store_results_as_dataset(
        predictions,
        predictions_raw,
        references,
        references_raw,
        model_name,
        end - start,
        get_model_size(whisper_asr.model),
        rwer,
        rcer,
        "msc.parquet",
    )
    clear_gpu_memory()

# %% ../nbs/02_msc.ipynb 16
def evaluate_faster_whisper_model_msc(
    model_name: str,  # The model name
    werlist: List[float],  # WER List
    cerlist: List[float],  # CER list
    modelsizelist: List[str],  # model size list
    timelist: List[float],  # time(s) list
    bs: int = 16,  # batch size. Default value is 16.
    compute_type: str = "float16",  # The compute type supported by faster-Whisper
    beam_size=1,  # beam size
) -> None:
    """A utility function for calculing WER in Common voice dataset provided a model name in huggingface.
    You can store a WER, CER, ModelSize, TimeList to calculate results cumulatively over different epochs
    """
    dataset = load_malayalam_speech_corpus_dataset()
    model = WhisperModel(model_name, device="cuda", compute_type=compute_type)

    predictions = []
    references = []
    predictions_raw = []
    references_raw = []

    start = time.time()
    for x in tqdm(dataset):
        segments, info = model.transcribe(x["audio"]["array"], beam_size=beam_size)
        predictions_raw.append(" ".join([segment.text for segment in segments]))
        predictions.append(normalizer(" ".join([segment.text for segment in segments])))
        references_raw.append(x["transcript"])
        references.append(normalizer(x["transcript"]))

    end = time.time()
    print(f"Total time taken: {end - start}")
    timelist.append(end - start)

    rwer = wer(references, predictions)
    rwer = round(100 * rwer, 2)
    werlist.append(rwer)
    print(f"The WER of model: {rwer}")

    rcer = cer(references, predictions)
    rcer = round(100 * rcer, 2)
    cerlist.append(rcer)
    print(f"The CER of model: {rcer}")

    # print(f"The model size is: {get_model_size(whisper_asr.model)}")
    # modelsizelist.append(get_model_size(whisper_asr.model))
    # df["model_size"] = get_model_size(whisper_asr.model)

    # save_name = model_name.split("/")
    # print(save_name)
    # df.to_parquet(f"{save_name[0]}_{save_name[1]}_msc.parquet")
    store_results_as_dataset(
        predictions,
        predictions_raw,
        references,
        references_raw,
        model_name,
        end - start,
        None,
        rwer,
        rcer,
        "msc.parquet",
    )

    clear_gpu_memory()
